{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc\n",
    "import ete3\n",
    "import os\n",
    "import re\n",
    "import linecache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import subprocess\n",
    "import colorlover as cl\n",
    "import plotly\n",
    "import plotly.plotly as ptl\n",
    "from plotly import graph_objs as go\n",
    "import pyparsing as pp\n",
    "\n",
    "plotly_accession = open('/Users/thiberio/plotly_accession').read().split()\n",
    "ptl.sign_in(plotly_accession[0], plotly_accession[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aggregate(object):\n",
    "    \n",
    "    def __init__(self, reference_tree, gene_tree_folder, aggregate_folder, reconciliation_folder,\n",
    "                 overall_tree_support_thresh=80,\n",
    "                 branch_support_thresh=95, \n",
    "                 ranger_confidence_threshold=0.9,\n",
    "                 leaves_allowed=False):\n",
    "        if type(reference_tree) is str:\n",
    "            self.species_tree            = ete3.Tree(reference_tree, format=1)\n",
    "        else:\n",
    "            self.species_tree            = reference_tree.copy()\n",
    "        self.overall_tree_support_thresh = overall_tree_support_thresh\n",
    "        self.support_threshold           = branch_support_thresh\n",
    "        self.ranger_confidence_threshold = ranger_confidence_threshold\n",
    "        self.leaves_allowed              = leaves_allowed\n",
    "        self.gene_tree_folder            = gene_tree_folder\n",
    "        self.aggregate_folder            = aggregate_folder\n",
    "        self.reconciliation_folder       = reconciliation_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def match_rooting(self, reference_root, tree_to_root):\n",
    "    tmp_tree = tree_to_root.copy()\n",
    "    for node in sorted( reference_root.children, key=len ):\n",
    "        if node.is_leaf():\n",
    "            leaf = tmp_tree.get_leaves_by_name(node.name)[0]\n",
    "            tmp_tree.set_outgroup(leaf)\n",
    "            return tmp_tree\n",
    "        else:\n",
    "            is_it_monophyletic, clade_type, fucking_up = tmp_tree.check_monophyly(\n",
    "                node.get_leaf_names(), \n",
    "                'name',\n",
    "                unrooted=False\n",
    "            )\n",
    "            if is_it_monophyletic:\n",
    "                equivalent = tmp_tree.get_common_ancestor(node.get_leaf_names())\n",
    "                tmp_tree.set_outgroup(equivalent)\n",
    "            else:\n",
    "                tmp_tree.set_outgroup(fucking_up.pop())\n",
    "                equivalent = tmp_tree.get_common_ancestor(node.get_leaf_names())\n",
    "                tmp_tree.set_outgroup(equivalent)\n",
    "\n",
    "            return tmp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def name_branches_as_reconciliation(self, reconciliation_file, tree):\n",
    "    branches         = re.findall('^(m\\d+) = LCA\\[(\\S+), (\\S+)\\]:', reconciliation_file, re.M)\n",
    "    duplicated_names = {}\n",
    "    for name, leaf1, leaf2 in branches:\n",
    "        node = tree.get_common_ancestor(leaf1, leaf2)\n",
    "        if node.name:\n",
    "            duplicated_names[name] = node.name\n",
    "            continue\n",
    "        node.name = name\n",
    "        node.add_feature('ranger_name', name)\n",
    "    return tree, duplicated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def parse_aggregated(self, group):\n",
    "    if not os.path.isdir('%s/%s' % (self.reconciliation_folder, group)) \\\n",
    "    or not os.path.isfile('%s/%s' % (self.aggregate_folder, group)):\n",
    "        return {group:None}\n",
    "\n",
    "    aggregated = open('%s/%s' % (self.aggregate_folder, group)).read()\n",
    "    with cd('%s/%s' % (self.reconciliation_folder, group)):\n",
    "        gene_tree     = {'named':ete3.Tree(linecache.getline('%s.output1' %group, 8), format=1)}\n",
    "\n",
    "    gene_tree['support'] = self.match_rooting(\n",
    "        gene_tree['named'],\n",
    "        ete3.Tree('%s/%s.treefile' % (self.gene_tree_folder, group))\n",
    "    )\n",
    "    gene_tree, duplicated_names = self.name_branches_as_reconciliation(aggregated, gene_tree['support'])\n",
    "    gene_tree.add_feature('group', group)\n",
    "    \n",
    "    ufboot_distribution = [node.support for node in gene_tree.traverse() if not node.is_leaf()]\n",
    "    if np.percentile(ufboot_distribution, 25) < self.overall_tree_support_thresh:\n",
    "        return {group:None}\n",
    "\n",
    "    num_replicates = float(re.match('Processed (\\d+) files', aggregated).group(1))\n",
    "\n",
    "    if not self.leaves_allowed:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = ([^0]\\d+?)\\], \\[Most Frequent mapping --> (n\\d+), \\\n",
    "(\\d+) times\\], \\[Most Frequent recipient --> (n\\d+), (\\d+) times\\].', aggregated, re.M)\n",
    "    else:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = ([^0]\\d+?)\\], \\[Most Frequent mapping --> (\\S+), \\\n",
    "(\\d+) times\\], \\[Most Frequent recipient --> (\\S+), (\\d+) times\\].',   aggregated, re.M)\n",
    "\n",
    "    selected_transfers = []\n",
    "    for donor_map_name, ranger_confidence, donor_name, ranger_confidence_donor,\\\n",
    "    recipient_name, ranger_confidence_recipient in transfers:\n",
    "        if donor_map_name in duplicated_names:\n",
    "            donor_map = gene_tree.search_nodes(name=duplicated_names[donor_map_name])[0]\n",
    "        else:\n",
    "            donor_map = gene_tree.search_nodes(name=donor_map_name)[0]\n",
    "\n",
    "        recipient_map_search = re.search(\n",
    "            '^({children[0]}|{children[1]}).*Most Frequent mapping --> {recipient}'.format(\n",
    "                recipient=recipient_name,\n",
    "                children=[child.name for child in donor_map.children]),\n",
    "            aggregated, re.M)\n",
    "        \n",
    "        if recipient_map_search:\n",
    "            recipient_map_name = recipient_map_search.group(1)\n",
    "            if not all([donor_name, recipient_name, donor_map_name, recipient_map_name]):\n",
    "                continue\n",
    "            /.append({'donor':donor_name, 'recipient':recipient_name,\n",
    "                                       'donor_map':donor_map_name, 'recipient_map':recipient_map_name,\n",
    "                                       'bipartition_support':donor_map.support,\n",
    "                                       'ranger_confidence':int(ranger_confidence),\n",
    "                                       'ranger_confidence_donor':int(ranger_confidence_donor),\n",
    "                                       'ranger_confidence_recipient':int(ranger_confidence_recipient)})\n",
    "    transfers_df = pd.DataFrame(selected_transfers)\n",
    "    transfers_df['family'] = group\n",
    "    return [transfers_df, gene_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def assess_dtl_dist(self, df, assess_donor_dtl=True, assess_recipient_dtl=False):\n",
    "    transfer_df = df.copy()\n",
    "    \n",
    "    if assess_donor_dtl:\n",
    "        donor_subtrees      = []\n",
    "        donor_maps          = []\n",
    "        donor_subtree_sizes = []\n",
    "        for donor_map in transfer_df.donor_map.unique():\n",
    "            donor_maps.append(donor_map)\n",
    "            gene_donor_branch = next(gene_tree.iter_search_nodes(name=donor_map))\n",
    "            donor_subtrees.append(gene_donor_branch.write(format=9))\n",
    "            donor_subtree_sizes.append(len(gene_donor_branch))\n",
    "\n",
    "        with open('tmp_ranger.input', 'w') as out:\n",
    "            out.write('%s\\n' % self.species_tree.write(format=9))\n",
    "            out.write('\\n'.join(donor_trees))\n",
    "\n",
    "        subprocess.call([\n",
    "            '/work/ranger/CorePrograms/Ranger-DTL.mac', \n",
    "            '-q',\n",
    "            '-i', 'tmp_ranger.input',\n",
    "            '-o', 'tmp_ranger.output'\n",
    "        ])\n",
    "        \n",
    "        for donor_map, subtree_size, dtl_cost in zip(\n",
    "                 donor_maps,\n",
    "                 donor_subtree_sizes,\n",
    "                 re.findall('^The minimum reconciliation cost is: (\\d+)',\n",
    "                            open('tmp_ranger.output').read(),\n",
    "                            re.M)):\n",
    "            transfer_df.loc[transfer_df.donor_map==donor_map,\n",
    "                            'donor_dtl_size_ratio'] = int(reconciliation_cost)/subtree_size\n",
    "        \n",
    "\n",
    "    return transfer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def assess_dtl_cost(self, df, assess_donor_dtl=True, assess_recipient_dtl=False):\n",
    "    transfer_df = df.copy()\n",
    "\n",
    "    if assess_donor_dtl:\n",
    "        donor_subtrees      = []\n",
    "        donor_maps          = []\n",
    "        donor_subtree_sizes = []\n",
    "        for group in transfer_df.family.unique():\n",
    "            with cd('%s/%s' % (self.reconciliation_folder, group)):\n",
    "                gene_tree = ete3.Tree(linecache.getline('%s.output1' %group, 8), format=1)\n",
    "            for donor_map in transfer_df.loc[transfer_df.family==group,\n",
    "                                             'donor_map'].unique():\n",
    "                donor_maps.append([group, donor_map])\n",
    "                gene_donor_branch = next(gene_tree.iter_search_nodes(name=donor_map))\n",
    "                donor_subtrees.append(gene_donor_branch.write(format=9))\n",
    "                donor_subtree_sizes.append(len(gene_donor_branch))\n",
    "\n",
    "        with open('tmp_ranger.input', 'w') as out:\n",
    "            out.write('%s\\n' % self.species_tree.write(format=9))\n",
    "            out.write('\\n'.join(donor_subtrees))\n",
    "\n",
    "        subprocess.call([\n",
    "            '/work/ranger/CorePrograms/Ranger-DTL.mac', \n",
    "            '-q',\n",
    "            '-i', 'tmp_ranger.input',\n",
    "            '-o', 'tmp_ranger.output'\n",
    "        ])\n",
    "        \n",
    "        for (group, donor_map), subtree_size, dtl_cost in zip(\n",
    "                 donor_maps,\n",
    "                 donor_subtree_sizes,\n",
    "                 re.findall('^The minimum reconciliation cost is: (\\d+)',\n",
    "                            open('tmp_ranger.output').read(),\n",
    "                            re.M)):\n",
    "            transfer_df.loc[(transfer_df.donor_map==donor_map) & (transfer_df.family==group),\n",
    "                            'donor_dtl_size_ratio'] = int(dtl_cost)/subtree_size\n",
    "        \n",
    "\n",
    "    return transfer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%add_to` not found.\n"
     ]
    }
   ],
   "source": [
    "%%add_to aggregate\n",
    "def name_species_tree_nodes(self, reconciliation_file):\n",
    "    species_tree_named_nodes = ete3.Tree(\n",
    "        linecache.getline(\n",
    "            reconciliation_file, 5\n",
    "        ), format=1)\n",
    "\n",
    "    for node in species_tree_named_nodes.traverse():\n",
    "        if node.is_leaf():\n",
    "            continue\n",
    "        else:\n",
    "            equivalent_node = self.species_tree.get_common_ancestor(node.get_leaf_names())\n",
    "            if equivalent_node.get_topology_id() == node.get_topology_id():\n",
    "                equivalent_node.name = node.name\n",
    "                equivalent_node.add_feature('ranger_name', node.name)\n",
    "            else:\n",
    "                print('missmatching node: %s' % node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def assess_transfer_distance(self, df):\n",
    "    transfer_df = df.copy()\n",
    "    grouped_by_donor_recipient  = transfer_df.groupby(['donor','recipient'])\n",
    "    for donor, recipient in grouped_by_donor_recipient.groups:\n",
    "        transfer_df.loc[(transfer_df.donor==donor) & \n",
    "                        (transfer_df.recipient==recipient),\n",
    "                        'donor_recipient_distance'] = self.species_tree.get_distance(donor, recipient)\n",
    "\n",
    "    for donor in transfer_df.donor.unique():\n",
    "        transfer_df.loc[transfer_df.donor==donor,\n",
    "                        'donor_depth'] = self.species_tree.get_distance(donor, topology_only=True)\n",
    "        transfer_df.loc[transfer_df.donor==donor,\n",
    "                        'donor_subtree_size'] = len(\n",
    "            next(self.species_tree.iter_search_nodes(ranger_name=donor))\n",
    "        )\n",
    "\n",
    "    for recipient in transfer_df.recipient.unique():\n",
    "        transfer_df.loc[transfer_df.recipient==recipient,\n",
    "                        'recipient_depth'] = self.species_tree.get_distance(recipient, topology_only=True)\n",
    "        transfer_df.loc[transfer_df.recipient==recipient,\n",
    "                        'recipient_subtree_size'] = len(\n",
    "            next(self.species_tree.iter_search_nodes(ranger_name=recipient))\n",
    "        )\n",
    "    \n",
    "    transfer_df['donor_depth/size_ratio']     = transfer_df['donor_depth'] / transfer_df['donor_subtree_size']\n",
    "    transfer_df['recipient_depth/size_ratio'] = transfer_df['recipient_depth'] / transfer_df['recipient_subtree_size']\n",
    "    return transfer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def map_taxonomic_level(self, df, taxa_table=None):\n",
    "    ncbi     = ete3.NCBITaxa()\n",
    "\n",
    "    taxa_df = pd.read_csv(taxa_table, sep='\\t')\n",
    "    taxa_df['Unnamed: 0'] = taxa_df['Unnamed: 0'].apply(lambda x: x.replace('_', '').split('.')[0])\n",
    "    taxa_df['accession'] = taxa_df['accession'].apply(lambda x: x.replace('_', '').split('.')[0])\n",
    "    taxa_df.set_index('Unnamed: 0', inplace=True)\n",
    "    \n",
    "    taxonomy_df = pd.DataFrame()\n",
    "\n",
    "    for leaf in self.species_tree.get_leaf_names():\n",
    "        if leaf in taxa_df.index:\n",
    "            node_name = taxa_df.index[taxa_df.index == leaf][0]\n",
    "        elif leaf in taxa_df.accession.values:\n",
    "            node_name = taxa_df.query('accession==@leaf').index[0]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        if pd.notnull(taxa_df.loc[node_name, 'taxid']):\n",
    "            taxid = taxa_df.loc[node_name, 'taxid']\n",
    "            lineage = {j:i\n",
    "                       for i, j in ncbi.get_rank(\n",
    "                           ncbi.get_lineage(taxid)).items()\n",
    "                      }\n",
    "            lineage['leaf_name'] = leaf\n",
    "            taxonomy_df = taxonomy_df.append(lineage, ignore_index=True)\n",
    "    taxonomy_df.set_index('leaf_name', inplace=True)\n",
    "    \n",
    "    to_drop = []\n",
    "    for column in taxonomy_df.columns:\n",
    "        if column not in ['class', 'species', 'superkingdom', 'genus',\n",
    "                          'order', 'phylum',  'family',       'kingdom']:\n",
    "            to_drop.append(column)\n",
    "    taxonomy_df.drop(to_drop, axis='columns', inplace=True)\n",
    "\n",
    "    transfer_df = df.copy()\n",
    "    for index, row in transfer_df.iterrows():\n",
    "        donor_descendants     = next(\n",
    "            self.species_tree.iter_search_nodes(ranger_name=row.donor)\n",
    "        ).get_leaf_names()\n",
    "        recipient_descendants = next(\n",
    "            self.species_tree.iter_search_nodes(ranger_name=row.recipient)\n",
    "        ).get_leaf_names()\n",
    "                \n",
    "        donor_taxonomy = taxonomy_df.loc[[taxon for taxon in donor_descendants if taxon in taxonomy_df.index]]\n",
    "        recipient_taxonomy = taxonomy_df.loc[[taxon for taxon  in recipient_descendants if taxon in taxonomy_df.index]]\n",
    "\n",
    "        if not donor_taxonomy.shape[0] or not recipient_taxonomy.shape[0]:\n",
    "            continue\n",
    "        \n",
    "        donor_taxonomy.dropna(axis=1, how='any', inplace=True)\n",
    "        recipient_taxonomy.dropna(axis=1, how='any', inplace=True)\n",
    "        \n",
    "        donor_taxonomy = next(donor_taxonomy.loc[:,\n",
    "                                                 np.invert(donor_taxonomy.T.duplicated().values)\n",
    "                                                ].iterrows())[1]\n",
    "        recipient_taxonomy = next(recipient_taxonomy.loc[:,\n",
    "                                                         np.invert(recipient_taxonomy.T.duplicated().values)\n",
    "                                                        ].iterrows())[1]\n",
    "\n",
    "        common_ranks = donor_taxonomy.index.intersection(recipient_taxonomy.index)\n",
    "\n",
    "        for rank in ['species', 'genus',  'family',  'order',\n",
    "                     'class',   'phylum', 'kingdom', 'superkingdom']:\n",
    "            if rank in common_ranks[donor_taxonomy[common_ranks]==recipient_taxonomy[common_ranks]]:\n",
    "                break\n",
    "        \n",
    "        transfer_df.loc[index, 'transfer_level'] = rank\n",
    "        \n",
    "    return(transfer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def cluster_redundant_transfers(self, df):\n",
    "    extended_df =  df.copy()\n",
    "    extended_df['donor_ancestry'] = extended_df.apply(\n",
    "        lambda row:\\\n",
    "        [ancestor.name for ancestor in next(\n",
    "            self.species_tree.iter_search_nodes(name=row.donor)).get_ancestors()],\n",
    "        axis=1)\n",
    "    extended_df['recipient_ancestry'] = extended_df.apply(\n",
    "        lambda row:\\\n",
    "        [ancestor.name for ancestor in next(\n",
    "            self.species_tree.iter_search_nodes(name=row.recipient)).get_ancestors()],\n",
    "        axis=1)\n",
    "\n",
    "    clusters = []\n",
    "    for name, row in extended_df.iterrows():\n",
    "        matching_transfers = extended_df[(\n",
    "                    (extended_df.donor_ancestry.apply(lambda x: row.donor in x)) |\n",
    "                    (extended_df.donor == row.donor)\n",
    "                ) &\n",
    "                (\n",
    "                    (extended_df.recipient_ancestry.apply(lambda x: row.recipient in x)) |\n",
    "                    (extended_df.recipient == row.recipient)\n",
    "                )].index\n",
    "        existing_cluster = False\n",
    "        for index, cluster in enumerate(clusters):\n",
    "            if not cluster.isdisjoint(matching_transfers):\n",
    "                existing_cluster = True\n",
    "                clusters[index].update(matching_transfers)\n",
    "                break\n",
    "        if not existing_cluster:\n",
    "            clusters.append(set(matching_transfers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def interactive_dynamic_plot(self, df):\n",
    "    tracers = []\n",
    "    max_x   = 0\n",
    "    max_y   = 0\n",
    "    rank_order = ['species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom']\n",
    "    rank_color = dict(zip(rank_order, np.linspace(0,1,15)[1::2]))\n",
    "    rank_color['superkingdom'] = rank_color['kingdom']\n",
    "\n",
    "    colors = cl.scales['9']['qual']['Paired']\n",
    "    colorscale = []\n",
    "    for pos, value in enumerate(np.linspace(0,1,8)):\n",
    "        colorscale.append([value, colors[pos]])\n",
    "        colorscale.append([value, colors[pos+1]])\n",
    "\n",
    "    for group in df.family.unique():\n",
    "        tracer = {'x':[], 'y':[], 'text':[], 'marker_color':[], 'marker_size':10}\n",
    "        group_number = int(group.split('_')[0])\n",
    "        for index, row in df.query('family==@group').iterrows():\n",
    "            tracer['x'   ].append(row.donor_recipient_distance)\n",
    "            tracer['y'   ].append(row['donor_depth/size_ratio'])\n",
    "            tracer['text'].append('group_%i#%i' % (group_number, index))\n",
    "            tracer['marker_color'].append(rank_color[row.transfer_level]\n",
    "                                          if pd.notnull(row.transfer_level) else 1)\n",
    "    \n",
    "        if np.max(tracer['x']) > max_x:\n",
    "            max_x = np.max(tracer['x'])\n",
    "        if np.max(tracer['y']) > max_y:\n",
    "            max_y = np.max(tracer['y'])\n",
    "        tracer = go.Scatter(x=tracer['x'],\n",
    "                            y=tracer['y'],\n",
    "                            mode='markers',\n",
    "                            text=tracer['text'],\n",
    "                            name='group_%s' % group.split('_')[0],\n",
    "                            hoverinfo='text', showlegend=True,\n",
    "                            marker=dict(size=tracer['marker_size'],\n",
    "                                        color=tracer['marker_color'],\n",
    "                                        colorscale=colorscale,\n",
    "                                        cmax=1,\n",
    "                                        cmin=0,\n",
    "                                        symbol='circle',\n",
    "                                        opacity=0.7)\n",
    "                           )\n",
    "        tracers.append(tracer)\n",
    "\n",
    "    tracers = sorted(tracers, key = lambda x: int(x['name'].split('_')[1]))\n",
    "    \n",
    "    layout    = go.Layout(\n",
    "        title='Interactive index HGT candidates plot!',\n",
    "        hovermode='closest',\n",
    "        width=1500, height=1000,\n",
    "        xaxis=dict(title='Donor-Recipient distance', \n",
    "                   autorange=False, \n",
    "                   range=[0, max_x+max_x*0.01]),\n",
    "        yaxis=dict(title='Donor depth/size ratio', \n",
    "                   autorange=False, \n",
    "                   range=[0, max_y+max_y*0.01]),\n",
    "        updatemenus=[\n",
    "            {'buttons':[{'label':'Show all',\n",
    "                         'method':'restyle',\n",
    "                         'args': [ 'visible', True]},\n",
    "                        {'label':'Hide all',\n",
    "                         'method':'restyle',\n",
    "                         'args': [ 'visible', ['legendonly']*len(tracers)+[True]]}]}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    tracers.append(go.Scatter(x=[max_x],\n",
    "                             y=[max_y],\n",
    "                             mode='markers',\n",
    "                             name='colorbar',\n",
    "                             showlegend=False,\n",
    "                             marker=dict(size=10,\n",
    "                                        color=0,\n",
    "                                        symbol='circle',\n",
    "                                        opacity=0.0,\n",
    "                                        colorscale=colorscale,\n",
    "                                        cmin=0,\n",
    "                                        cmax=1,\n",
    "                                        colorbar=dict(title='HGT within:',\n",
    "                                                      x=1.25,\n",
    "                                                      titleside = 'top',\n",
    "                                                      tickvals = np.linspace(0,1,15)[1::2],\n",
    "                                                      ticktext = rank_order,\n",
    "                                                      ticks = 'outside')\n",
    "                                        )\n",
    "                           )\n",
    "                  )\n",
    "    \n",
    "    fig       = go.Figure(data=tracers, layout=layout)\n",
    "    plot      = plotly.offline.plot(fig, filename='./test.html', auto_open=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%add_to` not found.\n"
     ]
    }
   ],
   "source": [
    "%%add_to aggregate\n",
    "def visualize_in_figtree(self, df, taxa_table=None):\n",
    "    ncbi     = ete3.NCBITaxa()\n",
    "\n",
    "    taxa_df = pd.read_csv(taxa_table, sep='\\t')\n",
    "    taxa_df['Unnamed: 0'] = taxa_df['Unnamed: 0'].apply(lambda x: x.replace('_', '').split('.')[0])\n",
    "    taxa_df['accession'] = taxa_df['accession'].apply(lambda x: x.replace('_', '').split('.')[0])\n",
    "    taxa_df.set_index('Unnamed: 0', inplace=True)\n",
    "    \n",
    "    out  = open('species_tree-hgt.figTree', 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(self.species_tree))\n",
    "    branch_names = {}\n",
    "    for count, node in enumerate(self.species_tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            if node.name in taxa_df.index:\n",
    "                node_name = taxa_df.index[taxa_df.index == node.name][0]\n",
    "            elif node.name in taxa_df.accession.values:\n",
    "                node_name = taxa_df.query('accession==@node.name').index[0]\n",
    "            else:\n",
    "                out.write('\\t%s\\n' %(node.name))\n",
    "                continue\n",
    "                \n",
    "            comment = ['source_name=\"%s\"' % taxa_df.loc[node_name, 'Organism']]\n",
    "            if pd.isnull(taxa_df.loc[node_name, 'taxid']):\n",
    "                out.write('\\t%s ' %(node.name))\n",
    "            else:\n",
    "                taxid = taxa_df.loc[node_name, 'taxid']\n",
    "                lineage = {j:i\n",
    "                           for i, j in ncbi.get_rank(\n",
    "                               ncbi.get_lineage(taxid)).items()\n",
    "                          }\n",
    "                lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "                out.write('\\t%s ' % (node.name))\n",
    "                for rank in ['class', 'phylum', 'order', 'family']:\n",
    "                    if rank in lineage:\n",
    "                        comment.append('tax_%s=\"%s\"' % (rank, lineage_names[lineage[rank]]))\n",
    "            out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "        else:\n",
    "            branch_names['_branch_%i_' % count] = '&support=%i,ranger_name=%s' %(node.support, node.ranger_name)\n",
    "            as_donor     = {}\n",
    "            as_recipient = {}\n",
    "            for index, row in df.query('donor==@node.ranger_name').iterrows():\n",
    "                if not row.family.split('_')[0] in as_donor:\n",
    "                    as_donor[row.family.split('_')[0]] = ''\n",
    "                as_donor[row.family.split('_')[0]] += '#%i' % index\n",
    "            for index, row in df.query('recipient==@node.ranger_name').iterrows():\n",
    "                if not row.family.split('_')[0] in as_recipient:\n",
    "                    as_recipient[row.family.split('_')[0]] = ''\n",
    "                as_recipient[row.family.split('_')[0]] += '#%i' % index\n",
    "\n",
    "            for group, role in as_donor.items():\n",
    "                branch_names['_branch_%i_' % count] += ',group_%s=donor%s' % (group, role)\n",
    "            for group, role in as_recipient.items():\n",
    "                if group in as_donor:\n",
    "                    branch_names['_branch_%i_' % count] += '/recipient%s' % role\n",
    "                else:\n",
    "                    branch_names['_branch_%i_' % count] += ',group_%s=recipient%s' % (group, role)\n",
    "\n",
    "            node.name = '_branch_%i_' % count\n",
    "\n",
    "\n",
    "    newick_text = self.species_tree.write(format=1, dist_formatter='%.10f')\n",
    "    for key, value in branch_names.items():\n",
    "        newick_text = newick_text.replace(key, '[%s]' % value)\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%add_to aggregate\n",
    "def visualize_in_gene_figtree(self, df, taxa_table=None):\n",
    "    ncbi     = ete3.NCBITaxa()\n",
    "\n",
    "    taxa_df = pd.read_csv(taxa_table, sep='\\t')\n",
    "    taxa_df['Unnamed: 0'] = taxa_df['Unnamed: 0'].apply(lambda x: x.split('.')[0])\n",
    "    taxa_df['accession'] = taxa_df['accession'].apply(lambda x: x.split('.')[0])\n",
    "    taxa_df.set_index('Unnamed: 0', inplace=True)\n",
    "    \n",
    "    folder = 'highlighted_gene_trees'\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    else:\n",
    "        os.system('rm -rf %s/*' % folder)\n",
    "    \n",
    "    for group in df.family.unique():\n",
    "        group_df = df.query('family==@group')\n",
    "        group_num   = int(group.split('_')[0])\n",
    "        newick_text = open('gene_trees/%s.treefile.rooted' % group).read()\n",
    "        gene_tree   = ete3.Tree(re.sub('\\[.*\\];$', ';', newick_text.strip(), flags=re.M))\n",
    "        for leaf in gene_tree.get_leaves():\n",
    "            if leaf.name.count('_') == 1:\n",
    "                gene, genome = leaf.name.split('_')\n",
    "            elif leaf.name.count('_') > 1 and re.search('GC[AF]_', leaf.name):\n",
    "                gene, genome = re.search('^([^.]+).+?(GC[AF]_\\d+)', leaf.name, re.M).groups()\n",
    "            elif leaf.name.count('_') == 2 and re.search('_PRJ', leaf.name):\n",
    "                gene, genome = re.search('^(.+)_(PRJ.+)$', leaf.name, re.M).groups()\n",
    "            else:\n",
    "                print(leaf.name)\n",
    "            gene = gene.split('.')[0]\n",
    "            leaf.add_feature('true_name', leaf.name)\n",
    "            leaf.add_feature('genome', genome)\n",
    "            leaf.name = '%s_%s' % (genome.replace('_', ''), gene.replace('_', ''))\n",
    "        \n",
    "        tmp = self.name_branches_as_reconciliation(open('ranger/%s/%s.output1' % (group, group)).read(),\n",
    "                                                   gene_tree)\n",
    "        out  = open('%s/group_%i-hgt.figTree' % (folder, group_num), 'w')\n",
    "        out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(gene_tree))\n",
    "        branch_names = {}\n",
    "        for count, node in enumerate(tmp[0].traverse()):\n",
    "\n",
    "            if node.is_leaf():\n",
    "                if node.genome in taxa_df.index:\n",
    "                    node_name = node.genome\n",
    "                elif node.genome in taxa_df.accession.values:\n",
    "                    node_name = taxa_df.query('accession==@node.genome').index[0]\n",
    "                else:\n",
    "                    out.write('\\t%s\\n' %(node.true_name))\n",
    "                    continue\n",
    "\n",
    "                comment = ['source_name=\"%s\"' % taxa_df.loc[node_name, 'Organism']]\n",
    "                if pd.isnull(taxa_df.loc[node_name, 'taxid']):\n",
    "                    out.write('\\t%s ' %(node.name))\n",
    "                else:\n",
    "                    taxid = taxa_df.loc[node_name, 'taxid']\n",
    "                    lineage = {j:i\n",
    "                               for i, j in ncbi.get_rank(\n",
    "                                   ncbi.get_lineage(taxid)).items()\n",
    "                              }\n",
    "                    lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "                    out.write('\\t%s ' % (node.name))\n",
    "                    for rank in ['class', 'phylum', 'order', 'family']:\n",
    "                        if rank in lineage:\n",
    "                            comment.append('tax_%s=\"%s\"' % (rank, lineage_names[lineage[rank]]))\n",
    "                out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "            else:\n",
    "                branch_names['_branch_%i_' % count] = '&ranger_name=%s' %(node.ranger_name)\n",
    "                as_donor     = {}\n",
    "                as_recipient = {}\n",
    "                for index, row in group_df.query('donor_map==@node.ranger_name').iterrows():\n",
    "                    if not row.family.split('_')[0] in as_donor:\n",
    "                        as_donor[row.family.split('_')[0]] = ''\n",
    "                    as_donor[row.family.split('_')[0]] += '#%i' % index\n",
    "                for index, row in group_df.query('recipient_map==@node.ranger_name').iterrows():\n",
    "                    if not row.family.split('_')[0] in as_recipient:\n",
    "                        as_recipient[row.family.split('_')[0]] = ''\n",
    "                    as_recipient[row.family.split('_')[0]] += '#%i' % index\n",
    "\n",
    "                for group, role in as_donor.items():\n",
    "                    branch_names['_branch_%i_' % count] += ',role=donor%s' % role\n",
    "                for group, role in as_recipient.items():\n",
    "                    if group in as_donor:\n",
    "                        branch_names['_branch_%i_' % count] += '/recipient%s' % role\n",
    "                    else:\n",
    "                        branch_names['_branch_%i_' % count] += ',role=recipient%s' % role\n",
    "\n",
    "                node.name = '_branch_%i_' % count\n",
    "\n",
    "        newick_text = tmp[0].write(format=1, dist_formatter='%.10f')\n",
    "        for key, value in branch_names.items():\n",
    "            newick_text = newick_text.replace(key, '[%s]' % value)\n",
    "        out.write(';\\nend;\\n')\n",
    "        out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "        out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
