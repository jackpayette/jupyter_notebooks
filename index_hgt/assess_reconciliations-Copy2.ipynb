{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import linecache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import plotly\n",
    "import plotly.plotly as ptl\n",
    "from plotly import graph_objs as go\n",
    "import pyparsing as pp\n",
    "import subprocess\n",
    "\n",
    "plotly_accession = open('/Users/thiberio/plotly_accession').read().split()\n",
    "ptl.sign_in(plotly_accession[0], plotly_accession[1])\n",
    "\n",
    "os.chdir('/work/Alphas_and_Cyanos')\n",
    "\n",
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rooting(ref_tree, tree2):\n",
    "    tree_to_root = tree2.copy()\n",
    "    for node in sorted( ref_tree.children, key=len ):\n",
    "        if node.is_leaf():\n",
    "            leaf = tree_to_root.get_leaves_by_name(node.name)[0]\n",
    "            tree_to_root.set_outgroup(leaf)\n",
    "            break\n",
    "        else:\n",
    "            is_it_monophyletic, clade_type, fucking_up = tree_to_root.check_monophyly(node.get_leaf_names(), 'name', unrooted=False)\n",
    "            if is_it_monophyletic:\n",
    "                equivalent = tree_to_root.get_common_ancestor(node.get_leaf_names())\n",
    "                tree_to_root.set_outgroup(equivalent)\n",
    "            else:\n",
    "                tree_to_root.set_outgroup(fucking_up.pop())\n",
    "                equivalent = tree_to_root.get_common_ancestor(node.get_leaf_names())\n",
    "                tree_to_root.set_outgroup(equivalent)\n",
    "            break\n",
    "\n",
    "    return tree_to_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_branches(reconciliation_file, tree):\n",
    "    branches         = re.findall('^(m\\d+) = LCA\\[(\\S+), (\\S+)\\]:', reconciliation_file, re.M)\n",
    "    duplicated_names = {}\n",
    "    for name, leaf1, leaf2 in branches:\n",
    "        node = tree.get_common_ancestor(leaf1, leaf2)\n",
    "        if node.name:\n",
    "            duplicated_names[name] = node.name\n",
    "            continue\n",
    "        node.name = name\n",
    "    return tree, duplicated_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_aggregated(folder, threshold=0.9, leaves_allowed=False):\n",
    "    if not os.path.isdir(folder) or not os.path.isfile(\n",
    "            '/work/Alphas_and_Cyanos/aggregated/mad_roots-stricter_branch_lengths/%s' % folder):\n",
    "        return {folder:None}\n",
    "\n",
    "    aggregated = open(\n",
    "        '/work/Alphas_and_Cyanos/aggregated/mad_roots-stricter_branch_lengths/%s' % folder).read()\n",
    "    with cd(folder):\n",
    "        gene_tree     = {'named':ete3.Tree(linecache.getline('%s-MAD.ranger_out1' %folder, 8), format=1)}\n",
    "\n",
    "    gene_tree['support'] = match_rooting(\n",
    "        gene_tree['named'],\n",
    "        ete3.Tree('/work/Alphas_and_Cyanos/ranger_input_trees-no_long_branches/%s.tree' %folder))\n",
    "    gene_tree, duplicated_names = rename_branches(aggregated, gene_tree['support'])\n",
    "    \n",
    "    ufboot_distribution = [node.support for node in gene_tree.traverse() if not node.is_leaf()]\n",
    "    if np.percentile(ufboot_distribution, 25) < 80:\n",
    "        return {folder:None}\n",
    "\n",
    "    num_replicates = float(re.match('Processed (\\d+) files', aggregated).group(1))\n",
    "\n",
    "    if not leaves_allowed:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = [^0]\\d+?\\], \\[Most Frequent mapping --> (n\\d+), \\\n",
    "(\\d+) times\\], \\[Most Frequent recipient --> (n\\d+), (\\d+) times\\].', aggregated, re.M)\n",
    "    else:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = [^0]\\d+?\\], \\[Most Frequent mapping --> (\\S+), \\\n",
    "(\\d+) times\\], \\[Most Frequent recipient --> (\\S+), (\\d+) times\\].',   aggregated, re.M)\n",
    "\n",
    "    supported_transfers = []\n",
    "    for donor_map, donor, ranger_confidence_donor, recipient, ranger_confidence_recipient in transfers:\n",
    "        if int(ranger_confidence_donor)     < threshold*num_replicates or \\\n",
    "           int(ranger_confidence_recipient) < threshold*num_replicates:\n",
    "            continue\n",
    "        supported_transfers.append((donor_map, donor, recipient))\n",
    "\n",
    "    selected_transfers = []\n",
    "    for donor_map_name, donor_name, recipient_name in supported_transfers:\n",
    "        if donor_map_name in duplicated_names:\n",
    "            donor_map = gene_tree.search_nodes(name=duplicated_names[donor_map_name])[0]\n",
    "        else:\n",
    "            donor_map = gene_tree.search_nodes(name=donor_map_name)[0]\n",
    "        if donor_map.support < 95:\n",
    "            continue\n",
    "\n",
    "        recipient_map_search = re.search(\n",
    "            '^({children[0]}|{children[1]}).*Most Frequent mapping --> {recipient}'.format(\n",
    "                recipient=recipient_name,\n",
    "                children=[child.name for child in donor_map.children]),\n",
    "            aggregated, re.M)\n",
    "        \n",
    "        if recipient_map_search:\n",
    "            recipient_map_name = recipient_map_search.group(1)\n",
    "            if not all([donor_name, recipient_name, donor_map_name, recipient_map_name]):\n",
    "                continue\n",
    "            selected_transfers.append({'donor':donor_name, 'recipient':recipient_name,\n",
    "                                       'donor_map':donor_map_name, 'recipient_map':recipient_map_name})\n",
    "    return {folder:[selected_transfers, gene_tree]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_dtl_dist(tmp_input):\n",
    "    group, (transfer_data, gene_tree) = tmp_input\n",
    "    dtl_distances   = []\n",
    "    donor_trees     = []\n",
    "    recipient_trees = []\n",
    "    for transfer in transfer_data:\n",
    "        recipient_branch = gene_tree.search_nodes(name=transfer['recipient_map'])[0]\n",
    "        donor_branch     = recipient_branch.get_sisters()[0]\n",
    "\n",
    "        donor_trees.append(    donor_branch.write(    format=9))\n",
    "\n",
    "    #\n",
    "    # donor compatibility assessment\n",
    "    os.system( 'cp species_tree.template tmp_ranger-%s.input' %(multiprocessing.current_process().name))\n",
    "    out = open('tmp_ranger-%s.input' %multiprocessing.current_process().name, 'a')\n",
    "    out.write('\\n'.join(donor_trees))\n",
    "    out.close()\n",
    "    os.system('/work/ranger/CorePrograms/Ranger-DTL.mac -q -i tmp_ranger-%s.input -o tmp_ranger-%s.output' \n",
    "              % (multiprocessing.current_process().name,\n",
    "                 multiprocessing.current_process().name)\n",
    "             )\n",
    "    dtl_distances.extend(\n",
    "        [float(reconciliation_cost)/len(donor_tree) \n",
    "         for reconciliation_cost, donor_tree in zip(\n",
    "             re.findall('^The minimum reconciliation cost is: (\\d+)',\n",
    "                        open('tmp_ranger-%s.output' %multiprocessing.current_process().name).read(),\n",
    "                        re.M\n",
    "                       ),\n",
    "             donor_trees)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {group:dtl_distances}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>real code...</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jdc\n",
    "%run base_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'reference_tree', 'gene_tree_folder', 'aggregate_folder', and 'reconciliation_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6a99417da48c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0myeah\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'reference_tree', 'gene_tree_folder', 'aggregate_folder', and 'reconciliation_folder'"
     ]
    }
   ],
   "source": [
    "yeah = aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cd('reconciliations/mad_roots-stricter_branch_lengths'):\n",
    "    pool    = multiprocessing.Pool(processes=15)\n",
    "    results = pool.map(parse_aggregated, os.listdir('.'))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    transfers = {}\n",
    "    for filtered in results:\n",
    "        if  list(filtered.values()) != [None] and list(filtered.values())[0][0] != []:\n",
    "            transfers.update(filtered)\n",
    "\n",
    "out = open('aggregated/mad_transfers-test.pkl', 'wb')\n",
    "pkl.dump(transfers, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('aggregated/maxtic.constrains-test', 'w')\n",
    "for group, (transfer_data, gene_tree) in transfers.items():\n",
    "    for transfer in transfer_data:\n",
    "        out.write('%s\\t%s\\n' % (transfer['donor'], transfer['recipient']))\n",
    "out.close()\n",
    "\n",
    "subprocess.call(['python',\n",
    "                 '/work/ale/maxtic/MaxTiC.py',\n",
    "                 'rooted_partitions-with_named_branches.treefile',\n",
    "                 'aggregated/maxtic.constrains-test',\n",
    "                 'ls=180'])\n",
    "\n",
    "maxtic = pd.read_table('aggregated/maxtic.constrains-test_MT_output_partial_order',\n",
    "                       header=None,\n",
    "                       names=['donor', 'recipient', 'weight', 'no_idea'],\n",
    "                       sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtic_compatible_transfers = {}\n",
    "for group, (transfer_data, gene_tree) in transfers.items():\n",
    "    tmp_transfers = []\n",
    "    for transfer in transfer_data:\n",
    "        if maxtic[(maxtic.donor==transfer['donor']) & (maxtic.recipient==transfer['recipient'])].shape[0]:\n",
    "            tmp_transfers.append(transfer)\n",
    "    if tmp_transfers:\n",
    "        maxtic_compatible_transfers[group] = [tmp_transfers, gene_tree]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = multiprocessing.Pool(processes=18)\n",
    "results = pool.map(assess_dtl_dist, list(maxtic_compatible_transfers.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "donor_dtl_distances = {}\n",
    "for element in results:\n",
    "    donor_dtl_distances.update(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_tree         = ete3.Tree('rooted_partitions-with_named_branches.treefile', format=1)\n",
    "transfer_distances     = {}\n",
    "donor_distance_to_root = {}\n",
    "donor_complexity_ratio = {}\n",
    "for group, (transfer_data, gene_tree) in maxtic_compatible_transfers.items():\n",
    "    for transfer in transfer_data:\n",
    "        pair         = frozenset([transfer['donor'], transfer['recipient']])\n",
    "        donor_branch = reference_tree.search_nodes(name=transfer['donor']    )[0]\n",
    "        \n",
    "        if pair not in transfer_distances:\n",
    "            recipient_branch = reference_tree.search_nodes(name=transfer['recipient'])[0]\n",
    "            transfer_distances[pair] = donor_branch.get_distance(recipient_branch, topology_only=False)\n",
    "\n",
    "        if transfer['donor'] not in donor_distance_to_root:\n",
    "            tmp_dist = reference_tree.get_distance(\n",
    "                transfer['donor'],\n",
    "                topology_only=False\n",
    "            )\n",
    "            donor_distance_to_root[transfer['donor']] = tmp_dist\n",
    "            donor_subtree_complexity = sum([node.dist\n",
    "                                            for node in donor_branch.traverse()\n",
    "                                            if node.name != transfer['donor']])\n",
    "            tmp_dist = reference_tree.get_distance(\n",
    "                transfer['donor'],\n",
    "                topology_only=True\n",
    "            )            \n",
    "            donor_complexity_ratio[transfer['donor']] = tmp_dist/len(donor_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxtic.loc[(maxtic.donor==maxtic_compatible_transfers[group][0][position]['donor']) &\n",
    "                                (maxtic.recipient==maxtic_compatible_transfers[group][0][position]['recipient']), 'weight'].squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracer = {'color':[], 'x':[], 'y':[], 'text':[], 'marker_size':[]}\n",
    "for group in donor_dtl_distances.keys():\n",
    "    for position in range(len(donor_dtl_distances[group])):\n",
    "        if [maxtic_compatible_transfers[group][0][position]['donor'],\n",
    "            maxtic_compatible_transfers[group][0][position]['recipient']] not in maxtic_compatible:\n",
    "            continue\n",
    "\n",
    "        tracer['x'    ].append(\n",
    "            transfer_distances[frozenset(\n",
    "                [maxtic_compatible_transfers[group][0][position]['donor'],\n",
    "                 maxtic_compatible_transfers[group][0][position]['recipient']]\n",
    "            )]\n",
    "        )\n",
    "        tracer['y'    ].append(\n",
    "            donor_complexity_ratio[maxtic_compatible_transfers[group][0][position]['donor']]\n",
    "        )\n",
    "        tracer['text' ].append('%s-#%i' %(group, position))\n",
    "        tracer['color'].append(donor_dtl_distances[group][position])\n",
    "        \n",
    "        transfer_count = maxtic.loc[\n",
    "            (maxtic.donor==maxtic_compatible_transfers[group][0][position]['donor']) &\n",
    "            (maxtic.recipient==maxtic_compatible_transfers[group][0][position]['recipient']),\n",
    "            'weight'].squeeze()\n",
    "        tracer['marker_size'].append(10+transfer_count*0.7)\n",
    "\n",
    "\n",
    "color_range          = np.linspace(np.min(tracer['color']), np.max(tracer['color']), 100)\n",
    "tracer['color_bins'] = np.digitize(tracer['color'], color_range)\n",
    "tracer_df = pd.DataFrame.from_dict(tracer)\n",
    "\n",
    "binned_df = tracer_df.groupby(by='color_bins')\n",
    "\n",
    "bins        = []\n",
    "for bin in binned_df.groups.keys():\n",
    "    tmp_df = binned_df.get_group(bin)\n",
    "    bins.append(\n",
    "        go.Scatter(\n",
    "            x=tmp_df.x.values,\n",
    "            y=tmp_df.y.values,\n",
    "            mode='markers',\n",
    "            text=tmp_df.text.values,\n",
    "            name=str(round(color_range[bin-1], 4)),\n",
    "            hoverinfo='text',\n",
    "            showlegend=False,\n",
    "            marker=dict(\n",
    "                size=tmp_df.marker_size.values,\n",
    "                color=tmp_df.color.values,\n",
    "                colorscale='RdBu',\n",
    "                cmax=tracer_df.color.values.max(),\n",
    "                cmin=tracer_df.color.values.min(),\n",
    "                symbol='circle',\n",
    "                opacity=.7,\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "#\n",
    "# source: https://plot.ly/python/sliders/\n",
    "steps = [dict(label='All',\n",
    "                method='restyle',\n",
    "                args=[\n",
    "                    'visible', [True] * (len(bins) + 1)\n",
    "                ])\n",
    "]\n",
    "for i in range(len(bins)):\n",
    "    step = dict(label=bins[i]['name'],\n",
    "                method='restyle',\n",
    "                args=[\n",
    "#                    'visible', [False] * i + [True] * (len(bins) - i)\n",
    "                    'visible', [False]  * (len(bins))\n",
    "                ])\n",
    "    step['args'][1].append(True)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "slider = dict(steps=steps, currentvalue={'prefix':'Donor subtree DTL: '}, pad={'t':50})\n",
    "bins.append(\n",
    "    go.Scatter(\n",
    "        x=[np.min(tracer['x']), np.max(tracer['x'])],\n",
    "        y=[np.min(tracer['y']), np.max(tracer['y'])],\n",
    "        showlegend=False,\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10, \n",
    "            color=[0.5], \n",
    "            colorscale='RdBu', \n",
    "            cmax=np.max(tracer['color']), \n",
    "            cmin=np.min(tracer['color']), \n",
    "            symbol='circle', \n",
    "            opacity=0,\n",
    "            colorbar=dict(title='Donor subtree DTL cost')\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "layout    = go.Layout(\n",
    "    title='Donor/Recipient subtree reconciliation costs',\n",
    "    hovermode='closest',\n",
    "    width=1200, height=1000,\n",
    "    xaxis=dict(title='Donor-Recipient distance'),\n",
    "    yaxis=dict(title='Donor branch distance to root and donor subtree ratio'),\n",
    "    sliders=[slider])\n",
    "fig       = go.Figure(data=bins, layout=layout)\n",
    "plot      = plotly.offline.plot(fig, filename='./test.html', auto_open=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
