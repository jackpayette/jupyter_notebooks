{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/eggNOG\n"
     ]
    }
   ],
   "source": [
    "import ete3\n",
    "import re\n",
    "import itertools\n",
    "import multiprocessing\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import igraph as ig\n",
    "import pickle as pkl\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from scipy.stats            import mannwhitneyu\n",
    "from collections            import Counter\n",
    "\n",
    "ncbi = ete3.NCBITaxa()\n",
    "%cd /work/eggNOG/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_genomes = pd.read_csv('../kelsey/genomes.tab',\n",
    "                              sep='\\t',\n",
    "                              index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pd.DataFrame()\n",
    "for taxid in sampled_genomes.species_taxid.unique():\n",
    "    if pd.isna(taxid):\n",
    "        continue\n",
    "    lineages = lineages.append({tax_rank: tmp_taxid \n",
    "                                 for tmp_taxid, tax_rank in ncbi.get_rank(ncbi.get_lineage(taxid)).items()},\n",
    "                                ignore_index=True)\n",
    "lineages = lineages.reindex(columns=['class', 'family',  'genus', 'phylum',\n",
    "                                     'order', 'species', 'superkingdom']).copy()\n",
    "lineages = lineages.query('superkingdom == 2').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_groups  = pd.read_parquet('working_eggNOG_groups.parquet')\n",
    "working_trees   = pd.read_parquet('working_eggNOG_trees.parquet' )\n",
    "eggNOG_taxonomy = pd.read_parquet('eggNOG_taxonomy.parquet'      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances(group_id):\n",
    "    \n",
    "    tree = ete3.Tree(working_trees.loc[group_id, 'tree'])\n",
    "\n",
    "    leaf_names = []\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            leaf_names.append(node.name)\n",
    "        else:\n",
    "            node.name = 'node_%i' % count\n",
    "    leaf_names = np.array(leaf_names)\n",
    "\n",
    "    nodes         = []\n",
    "    children      = []\n",
    "    branch_length = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                nodes.append(         node.name)\n",
    "                children.append(     child.name)\n",
    "                branch_length.append(child.dist)\n",
    "\n",
    "    branch_length_df                  = pd.DataFrame()\n",
    "    branch_length_df['node']          = nodes\n",
    "    branch_length_df['child']         = children\n",
    "    branch_length_df['branch_length'] = branch_length\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges=branch_length_df[['node', \n",
    "                                                      'child', \n",
    "                                                      'branch_length']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights=True)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                                   target=leaf_names, \n",
    "                                                                   weights='weight'))\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxa_graph(dist_matrix, phyla):\n",
    "    triu_indices       = np.triu_indices_from(dist_matrix, k=1)\n",
    "    \n",
    "    edge_list                 = pd.DataFrame()\n",
    "    edge_list['phylum1']      = phyla[triu_indices[0]]\n",
    "    edge_list['phylum2']      = phyla[triu_indices[1]]\n",
    "    edge_list['sequence1']    = dist_matrix.index[triu_indices[0]]\n",
    "    edge_list['sequence2']    = dist_matrix.index[triu_indices[1]]\n",
    "    edge_list['distance']     = dist_matrix.values[triu_indices]\n",
    "    edge_list['inverse_dist'] = np.e**np.negative(edge_list.distance)\n",
    "\n",
    "    graph  = ig.Graph.TupleList(edges=edge_list[['sequence1', \n",
    "                                                 'sequence2', \n",
    "                                                 'inverse_dist']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights =True)\n",
    "    \n",
    "    return(edge_list, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_cluster(reference_phylum, minimal_freq_phyla, cluster_edges, cluster_nodes):\n",
    "    cluster_dists = pd.DataFrame(columns=['phylum', 'median', 'distances'])\n",
    "\n",
    "    for phylum1, phylum2 in itertools.combinations(minimal_freq_phyla, 2):\n",
    "        if   phylum1 == reference_phylum:\n",
    "            phylum = phylum2\n",
    "        elif phylum2 == reference_phylum:\n",
    "            phylum = phylum1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        inter_phyla = cluster_edges.loc[((cluster_edges.phylum1==phylum1)&(cluster_edges.phylum2==phylum2))|\\\n",
    "                                        ((cluster_edges.phylum2==phylum1)&(cluster_edges.phylum1==phylum2))]\n",
    "        indices     = np.unique(inter_phyla[['sequence1', 'sequence2']])\n",
    "        adjacencies = pd.DataFrame(data=0.0, index=indices, columns=indices)\n",
    "\n",
    "        indexer     = adjacencies.index.get_indexer\n",
    "\n",
    "        adjacencies.values[indexer(inter_phyla.sequence1), indexer(inter_phyla.sequence2)]  = inter_phyla.distance.values\n",
    "        adjacencies.values[indexer(inter_phyla.sequence2), indexer(inter_phyla.sequence1)] += inter_phyla.distance.values\n",
    "\n",
    "        tmp_closest_to_phylum = adjacencies.loc[cluster_nodes.loc[cluster_nodes.phylum==reference_phylum,   'name'],\n",
    "                                                cluster_nodes.loc[cluster_nodes.phylum==phylum, 'name']].sum()\n",
    "        tmp_closest_to_phylum.sort_values(inplace=True)\n",
    "        tmp_closest_to_phylum = tmp_closest_to_phylum.index[:5]\n",
    "\n",
    "        try:\n",
    "            distances_to_reference_phylum = adjacencies.loc[cluster_nodes.loc[cluster_nodes.phylum==reference_phylum,   'name'],\n",
    "                                                            tmp_closest_to_phylum].values.flatten()\n",
    "        except IndexError:\n",
    "            continue        \n",
    "\n",
    "        cluster_dists = cluster_dists.append(pd.Series(data =[phylum, \n",
    "                                                              np.median(distances_to_reference_phylum), \n",
    "                                                              distances_to_reference_phylum], \n",
    "                                                       index=['phylum', 'median', 'distances']),\n",
    "                                             ignore_index=True)\n",
    "    return(cluster_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phyla_evol_distances(group_id):    \n",
    "    dist_matrix = get_pairwise_distances(group_id)\n",
    "\n",
    "    taxids = [int(leaf.split('.')[0]) for leaf in dist_matrix.index]\n",
    "    phyla  = eggNOG_taxonomy.loc[taxids, 'phylum'].values.astype(int)\n",
    "\n",
    "    edge_list, graph  = create_taxa_graph(dist_matrix, phyla)\n",
    "\n",
    "    random.seed(12345)\n",
    "    clusters = graph.community_multilevel(weights='weight')\n",
    "\n",
    "    node_data = pd.DataFrame(columns=['name', 'phylum', 'cluster'],\n",
    "                             data   =zip(dist_matrix.index, \n",
    "                                         phyla, \n",
    "                                         clusters.membership)\n",
    "                            )\n",
    "    \n",
    "    cluster_evol_relations = {}\n",
    "    target_phyla = {1090, 1117, 1224, 200795, 976, 1134404, 1798710}\n",
    "\n",
    "    for cluster_num in set(clusters.membership):\n",
    "        \n",
    "        cluster_nodes      = node_data[node_data.cluster==cluster_num]\n",
    "        minimal_freq_phyla = [phylum for phylum, frequency in Counter(cluster_nodes.phylum).items() if frequency>=5 \\\n",
    "                                                                                                    and phylum > 0]\n",
    "       \n",
    "        if len( target_phyla.intersection( minimal_freq_phyla ) ) < 2:\n",
    "            continue\n",
    "        \n",
    "        cluster_evol_relations[cluster_num] = {}\n",
    "        \n",
    "        cluster_edges = edge_list.loc[(edge_list.sequence1.isin(cluster_nodes.name))&\n",
    "                                      (edge_list.sequence2.isin(cluster_nodes.name)),\n",
    "                                      ['phylum1', 'phylum2', 'sequence1', 'sequence2', 'distance']]\n",
    "\n",
    "        cluster_edges      = cluster_edges[(cluster_edges.phylum1.isin(minimal_freq_phyla)) &\\\n",
    "                                           (cluster_edges.phylum2.isin(minimal_freq_phyla))]\n",
    "        normalizer         = np.median(cluster_edges.distance)\n",
    "        cluster_edges      = cluster_edges[cluster_edges.phylum1 != cluster_edges.phylum2] \n",
    "\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        for ref_phylum in target_phyla.intersection(minimal_freq_phyla):\n",
    "            cluster_dists = assess_cluster(ref_phylum, \n",
    "                                           minimal_freq_phyla, \n",
    "                                           cluster_edges,\n",
    "                                           cluster_nodes)\n",
    "\n",
    "            cluster_dists.sort_values('median', inplace=True)\n",
    "            cluster_evol_relations[cluster_num][ref_phylum] = {'df':cluster_dists[['phylum', 'median']].copy(),\n",
    "                                                   'significant':False}\n",
    "            if not cluster_dists.shape[0]:\n",
    "                continue\n",
    "\n",
    "            cluster_evol_relations[cluster_num][ref_phylum]['df']['median']   /= normalizer\n",
    "            if cluster_dists.shape[0] == 1:\n",
    "                cluster_evol_relations[cluster_num][ref_phylum]['significant'] = True\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                hypothesis = mannwhitneyu(cluster_dists.iloc[0, 2], \n",
    "                                          cluster_dists.iloc[1, 2], \n",
    "                                          alternative='less')\n",
    "            except ValueError:\n",
    "                continue\n",
    "            else:\n",
    "                effect_size = hypothesis.statistic / (len(cluster_dists.iloc[0, 2])*len(cluster_dists.iloc[1, 2]))\n",
    "\n",
    "                if hypothesis.pvalue < 0.01 and effect_size < 0.2:\n",
    "                    cluster_evol_relations[cluster_num][ref_phylum]['significant'] = True\n",
    "    \n",
    "    return(group_id, cluster_evol_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 s, sys: 928 ms, total: 12.3 s\n",
      "Wall time: 12 s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# get_phyla_evol_distances('COG0499')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.7 ms, sys: 57.9 ms, total: 101 ms\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pool    = multiprocessing.Pool(processes=10, maxtasksperchild=5)\n",
    "results = pool.map_async(get_phyla_evol_distances, working_groups.group_id.values)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_results.pkl', 'wb') as out:\n",
    "    pkl.dump(results.get(), out)\n",
    "del(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
