{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ete3\n",
    "import re\n",
    "import community\n",
    "import networkx as nx\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn import manifold\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import igraph as ig\n",
    "import plotly\n",
    "import chart_studio.plotly as ptl\n",
    "import plotly.graph_objects as go\n",
    "import colorlover as cl\n",
    "from IPython.display import HTML\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import random\n",
    "from sklearn import mixture\n",
    "from collections import Counter\n",
    "import random\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "ptl.sign_in('lthiberiol', 'm15ikp59lt')\n",
    "ncbi = ete3.NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_genomes = pd.read_csv('../kelsey/genomes.tab',\n",
    "                              sep='\\t',\n",
    "                              index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = pd.DataFrame()\n",
    "for taxid in sampled_genomes.species_taxid.unique():\n",
    "    if pd.isna(taxid):\n",
    "        continue\n",
    "    lineages = lineages.append({tax_rank: tmp_taxid \n",
    "                                 for tmp_taxid, tax_rank in ncbi.get_rank(ncbi.get_lineage(taxid)).items()},\n",
    "                                ignore_index=True)\n",
    "lineages = lineages.reindex(columns=['class', 'family',  'genus', 'phylum',\n",
    "                                     'order', 'species', 'superkingdom']).copy()\n",
    "lineages = lineages.query('superkingdom == 2').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggNOG_sample = pd.read_csv('e5.bacteria.taxid_info.tsv',\n",
    "                            sep='\\t',\n",
    "                            comment='#',\n",
    "                            names=['Taxid', 'Sci.Name', 'Rank', 'Named Lineage', 'Taxid Lineage'],\n",
    "                            header=None,\n",
    "                            index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eggNOG_lineage = pd.DataFrame()\n",
    "for taxid in eggNOG_sample.index.unique():\n",
    "    if pd.isna(taxid):\n",
    "        continue\n",
    "    tmp = pd.Series({tax_rank: tmp_taxid \n",
    "                     for tmp_taxid, tax_rank in ncbi.get_rank(ncbi.get_lineage(taxid)).items()})\n",
    "    tmp.name = taxid\n",
    "    eggNOG_lineage = eggNOG_lineage.append(tmp)\n",
    "\n",
    "eggNOG_lineage = eggNOG_lineage.reindex(columns=['class', 'family',  'genus', 'phylum',\n",
    "                                                 'order', 'species', 'superkingdom']).copy()\n",
    "eggNOG_lineage = eggNOG_lineage.query('superkingdom == 2').copy()\n",
    "\n",
    "eggNOG_target_phyla = eggNOG_lineage[eggNOG_lineage.phylum.isin(lineages.phylum.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggNOG_groups = pd.read_csv('2_members.tsv',\n",
    "                            sep='\\t',\n",
    "                            header=None,\n",
    "                            usecols=[1,2,3,4],\n",
    "                            names=['group_id', 'num_proteins', 'num_taxa', 'members'])\n",
    "\n",
    "tmp           = eggNOG_groups.members.map(lambda cell: [int(taxid) \n",
    "                                                        for taxid in re.findall('(\\d+)\\.(?:[^,]+)', cell)])\n",
    "tmp.name      = 'taxa'\n",
    "eggNOG_groups = eggNOG_groups.join(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phyla_overlap(taxa):\n",
    "    #taxids = [int(_) for _ in taxa]\n",
    "    group_phyla = set(eggNOG_lineage.loc[taxa, 'phylum'].unique())\n",
    "    overlapped_phyla = group_phyla.intersection(lineages.phylum.unique())\n",
    "    return(overlapped_phyla)\n",
    "\n",
    "eggNOG_target_groups = eggNOG_groups[eggNOG_groups.taxa.map(lambda cell: \n",
    "                                                            True if len(get_phyla_overlap(cell)) > 1 \n",
    "                                                            else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggNOG_trees = pd.read_csv('2_trees.tsv',\n",
    "                           sep='\\t',\n",
    "                           header=None,\n",
    "                           usecols=[1,2,3],\n",
    "                           index_col=0,\n",
    "                           names=['group_id', 'fast', 'tree'])\n",
    "eggNOG_trees = eggNOG_trees.reindex(index=eggNOG_target_groups.group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggNOG_chloroflexi = eggNOG_lineage.query('phylum==200795').index\n",
    "eggNOG_cyano       = eggNOG_lineage.query('phylum==1117'  ).index\n",
    "\n",
    "chloroflexi_count = eggNOG_target_groups.taxa.map(lambda x: len(eggNOG_chloroflexi.intersection(set(x))))\n",
    "cyano_count       = eggNOG_target_groups.taxa.map(lambda x: len(eggNOG_cyano.intersection(set(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances(group_id):\n",
    "    \n",
    "    tree = ete3.Tree(eggNOG_trees.loc[group_id, 'tree'])\n",
    "\n",
    "    leaf_names = []\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            leaf_names.append(node.name)\n",
    "        else:\n",
    "            node.name = 'node_%i' % count\n",
    "    leaf_names = np.array(leaf_names)\n",
    "\n",
    "    nodes         = []\n",
    "    children      = []\n",
    "    branch_length = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                nodes.append(         node.name)\n",
    "                children.append(     child.name)\n",
    "                branch_length.append(child.dist)\n",
    "\n",
    "    branch_length_df                  = pd.DataFrame()\n",
    "    branch_length_df['node']          = nodes\n",
    "    branch_length_df['child']         = children\n",
    "    branch_length_df['branch_length'] = branch_length\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges=branch_length_df[['node', \n",
    "                                                      'child', \n",
    "                                                      'branch_length']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights=True)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                                   target=leaf_names, \n",
    "                                                                   weights='weight'))\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxa_graph(dist_matrix, phyla):\n",
    "    triu_indices       = np.triu_indices_from(dist_matrix, k=1)\n",
    "    \n",
    "    edge_list                 = pd.DataFrame()\n",
    "    edge_list['phylum1']      = phyla[triu_indices[0]]\n",
    "    edge_list['phylum2']      = phyla[triu_indices[1]]\n",
    "    edge_list['sequence1']    = dist_matrix.index[triu_indices[0]]\n",
    "    edge_list['sequence2']    = dist_matrix.index[triu_indices[1]]\n",
    "    edge_list['distance']     = dist_matrix.values[triu_indices]\n",
    "    edge_list['inverse_dist'] = np.e**np.negative(edge_list.distance)\n",
    "\n",
    "    graph  = ig.Graph.TupleList(edges=edge_list[['sequence1', \n",
    "                                                 'sequence2', \n",
    "                                                 'inverse_dist']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights =True)\n",
    "    \n",
    "    return(edge_list, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def assess_cluster(reference_phylum, minimal_freq_phyla, cluster_edges):\n",
    "#     cluster_dists = pd.DataFrame(columns=['phylum', 'median', 'distances'])\n",
    "\n",
    "#     for phylum1, phylum2 in itertools.combinations(minimal_freq_phyla, 2):\n",
    "#         if   phylum1 == reference_phylum:\n",
    "#             phylum = phylum2\n",
    "#         elif phylum2 == reference_phylum:\n",
    "#             phylum = phylum1\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "#         inter_phyla_dists = cluster_edges.loc[((cluster_edges.phylum1==phylum1)&(cluster_edges.phylum2==phylum2))|\\\n",
    "#                                               ((cluster_edges.phylum2==phylum1)&(cluster_edges.phylum1==phylum2)), \n",
    "#                                               'distance'].values\n",
    "\n",
    "#         try:\n",
    "#             phylum_3rd_quartile = np.median(inter_phyla_dists)\n",
    "#         except IndexError:\n",
    "#             continue        \n",
    "\n",
    "#         cluster_dists = cluster_dists.append(pd.Series(data=[phylum, phylum_3rd_quartile, inter_phyla_dists], \n",
    "#                                            index=['phylum', 'median', 'distances']),\n",
    "#                                  ignore_index=True)\n",
    "\n",
    "#     return(cluster_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_cluster(reference_phylum, minimal_freq_phyla, cluster_edges, cluster_nodes):\n",
    "    cluster_dists = pd.DataFrame(columns=['phylum', 'median', 'distances'])\n",
    "\n",
    "    for phylum1, phylum2 in itertools.combinations(minimal_freq_phyla, 2):\n",
    "        if   phylum1 == reference_phylum:\n",
    "            phylum = phylum2\n",
    "        elif phylum2 == reference_phylum:\n",
    "            phylum = phylum1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        #\n",
    "        # source: https://stackoverflow.com/questions/53246086/convert-list-of-edges-to-adjacency-matrix\n",
    "        #\n",
    "        inter_phyla = cluster_edges.loc[((cluster_edges.phylum1==phylum1)&(cluster_edges.phylum2==phylum2))|\\\n",
    "                                        ((cluster_edges.phylum2==phylum1)&(cluster_edges.phylum1==phylum2))]\n",
    "        indices     = np.unique(inter_phyla[['sequence1', 'sequence2']])\n",
    "        adjacencies = pd.DataFrame(data=0.0, index=indices, columns=indices)\n",
    "\n",
    "        indexer     = adjacencies.index.get_indexer\n",
    "\n",
    "        adjacencies.values[indexer(inter_phyla.sequence1), indexer(inter_phyla.sequence2)]  = inter_phyla.distance.values\n",
    "        adjacencies.values[indexer(inter_phyla.sequence2), indexer(inter_phyla.sequence1)] += inter_phyla.distance.values\n",
    "\n",
    "        tmp_closest_to_phylum = adjacencies.loc[cluster_nodes.loc[cluster_nodes.phylum==1117,   'name'],\n",
    "                                                cluster_nodes.loc[cluster_nodes.phylum==phylum, 'name']].sum()\n",
    "        tmp_closest_to_phylum.sort_values(inplace=True)\n",
    "        tmp_closest_to_phylum = tmp_closest_to_phylum.index[:5]\n",
    "\n",
    "        try:\n",
    "            distances_to_reference_phylum = adjacencies.loc[cluster_nodes.loc[cluster_nodes.phylum==1117,   'name'],\n",
    "                                                            tmp_closest_to_phylum].values.flatten()\n",
    "        except IndexError:\n",
    "            continue        \n",
    "\n",
    "        cluster_dists = cluster_dists.append(pd.Series(data =[phylum, \n",
    "                                                              np.median(distances_to_reference_phylum), \n",
    "                                                              distances_to_reference_phylum], \n",
    "                                                       index=['phylum', 'median', 'distances']),\n",
    "                                             ignore_index=True)\n",
    "    return(cluster_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phyla_evol_distances(group_id):    \n",
    "    dist_matrix = get_pairwise_distances(group_id)\n",
    "\n",
    "    taxids = [int(leaf.split('.')[0]) for leaf in dist_matrix.index]\n",
    "    phyla  = eggNOG_lineage.loc[taxids, 'phylum'].values.astype(int)\n",
    "\n",
    "    edge_list, graph  = create_taxa_graph(dist_matrix, phyla)\n",
    "\n",
    "    random.seed(12345)\n",
    "    clusters = graph.community_multilevel(weights='weight')\n",
    "\n",
    "    node_data = pd.DataFrame(columns=['name', 'phylum', 'cluster'],\n",
    "                             data   =zip(dist_matrix.index, \n",
    "                                         phyla, \n",
    "                                         clusters.membership)\n",
    "                            )\n",
    "\n",
    "    family_cyano_count     = sum(node_data.phylum==1117)\n",
    "    \n",
    "    cluster_evol_relations = {}\n",
    "\n",
    "    for cluster_num in set(clusters.membership):\n",
    "        cluster_nodes = node_data[node_data.cluster==cluster_num]\n",
    "\n",
    "        if sum(cluster_nodes.phylum==1117) < family_cyano_count*0.3:\n",
    "            continue\n",
    "        \n",
    "        cluster_edges = edge_list.loc[(edge_list.sequence1.isin(cluster_nodes.name))&\n",
    "                                      (edge_list.sequence2.isin(cluster_nodes.name)),\n",
    "                                      ['phylum1', 'phylum2', 'sequence1', 'sequence2', 'distance']]\n",
    "\n",
    "        minimal_freq_phyla = [phylum for phylum, frequency in Counter(cluster_nodes.phylum).items() if frequency>=5 \\\n",
    "                                                                                                    and phylum > 0]\n",
    "        cluster_edges      = cluster_edges[(cluster_edges.phylum1.isin(minimal_freq_phyla)) &\\\n",
    "                                           (cluster_edges.phylum2.isin(minimal_freq_phyla))]\n",
    "        normalizer         = np.median(cluster_edges.distance)\n",
    "        cluster_edges      = cluster_edges[cluster_edges.phylum1 != cluster_edges.phylum2] \n",
    "\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        cluster_dists = assess_cluster(1117, \n",
    "                                       minimal_freq_phyla, \n",
    "                                       cluster_edges,\n",
    "                                       cluster_nodes)\n",
    "        \n",
    "        cluster_dists.sort_values('median', inplace=True)\n",
    "        cluster_evol_relations[cluster_num]                  = {'df':cluster_dists[['phylum', 'median']].copy(),\n",
    "                                                                'significant':False}\n",
    "        if not cluster_dists.shape[0]:\n",
    "            continue\n",
    "\n",
    "        cluster_evol_relations[cluster_num]['df']['median'] /= normalizer\n",
    "        if cluster_dists.shape[0] == 1:\n",
    "            cluster_evol_relations[cluster_num]['significant'] = True\n",
    "            continue\n",
    "\n",
    "        hypothesis = mannwhitneyu(cluster_dists.iloc[0, 2], \n",
    "                                  cluster_dists.iloc[1, 2], \n",
    "                                  alternative='less')\n",
    "        effect_size = hypothesis.statistic / (len(cluster_dists.iloc[0, 2])*len(cluster_dists.iloc[1, 2]))\n",
    "        \n",
    "        if hypothesis.pvalue < 0.01 and effect_size < 0.2:\n",
    "            cluster_evol_relations[cluster_num]['significant'] = True\n",
    "    \n",
    "    return(group_id, cluster_evol_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# get_phyla_evol_distances('COG0499')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# get_phyla_evol_distances('COG2896')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups interesting to test distances between cyano and chloroflexi\n",
    "test_groups = eggNOG_target_groups[(chloroflexi_count>=10) & (cyano_count>=70)]\n",
    "\n",
    "test_groups = test_groups[test_groups.num_proteins<10_000]\n",
    "print(test_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pool    = multiprocessing.Pool(processes=15, maxtasksperchild=5)\n",
    "results = pool.map_async(get_phyla_evol_distances, test_groups.group_id.values)\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('less_than_10k_results.pkl', 'wb') as out:\n",
    "    pkl.dump(results.get(), out)\n",
    "del(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups interesting to test distances between cyano and chloroflexi\n",
    "test_groups = eggNOG_target_groups[(chloroflexi_count>=10) & (cyano_count>=70)]\n",
    "\n",
    "test_groups = test_groups[(20_000>test_groups.num_proteins)&(test_groups.num_proteins>10_000)]\n",
    "print(test_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pool     = multiprocessing.Pool(processes=2, maxtasksperchild=5)\n",
    "results  = pool.map_async(get_phyla_evol_distances, test_groups.group_id.values)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "with open('more_than_10k_results.pkl', 'wb') as out:\n",
    "    pkl.dump(results.get(), out)\n",
    "del(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
