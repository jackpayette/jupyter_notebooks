{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nobackup1b/users/thiberio/eggNOG\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import itertools\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import igraph as ig\n",
    "from IPython.display import HTML\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import random\n",
    "from collections import Counter\n",
    "import os\n",
    "import subprocess\n",
    "from scipy.stats import mannwhitneyu\n",
    "import ete3\n",
    "from copy import deepcopy\n",
    "from math import ceil\n",
    "\n",
    "ncbi = ete3.NCBITaxa()\n",
    "%run assess_connections-functions.ipynb\n",
    "\n",
    "%cd ~/work/eggNOG/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_genomes = pd.read_csv('../kelsey/genomes.tab',\n",
    "                              sep='\\t',\n",
    "                              index_col=0)\n",
    "\n",
    "lineages = pd.DataFrame()\n",
    "for taxid in sampled_genomes.species_taxid.unique():\n",
    "    if pd.isna(taxid):\n",
    "        continue\n",
    "    lineages = lineages.append({tax_rank: tmp_taxid \n",
    "                                 for tmp_taxid, tax_rank in ncbi.get_rank(ncbi.get_lineage(taxid)).items()},\n",
    "                                ignore_index=True)\n",
    "lineages = lineages.reindex(columns=['class', 'family',  'genus', 'phylum',\n",
    "                                     'order', 'species', 'superkingdom']).copy()\n",
    "lineages = lineages.query('superkingdom == 2').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_phyla = [phylum for phylum in lineages.phylum.unique().astype(int) if phylum > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_groups  = pd.read_parquet('working_eggNOG_groups.parquet', engine='fastparquet')\n",
    "working_trees   = pd.read_parquet('working_eggNOG_trees.parquet' , engine='fastparquet')\n",
    "eggNOG_taxonomy = pd.read_parquet('eggNOG_taxonomy.parquet'      , engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('all_results.pkl', 'rb') as _:\n",
    "    phylum_connections = pkl.load(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_connections     = []\n",
    "significant_connections = []\n",
    "\n",
    "for group_id, group_clusters in phylum_connections:\n",
    "    if not group_clusters:\n",
    "        continue\n",
    "    \n",
    "    for cluster_num, cluster_data in group_clusters.items():\n",
    "\n",
    "        for ref_phylum, phyla_dists in cluster_data.items():\n",
    "            \n",
    "            if not phyla_dists['df'].shape[0]:\n",
    "                continue\n",
    "\n",
    "            closest_phylum = phyla_dists['df'].iloc[0, 0]\n",
    "            if not closest_phylum in sampled_phyla:\n",
    "                continue\n",
    "\n",
    "            if phyla_dists['significant']:\n",
    "                significant_connections.append( (ref_phylum,\n",
    "                                                 phyla_dists['df'].iloc[0, 0],\n",
    "                                                 phyla_dists['df'].iloc[0, 1], \n",
    "                                                 '%s#%i' % (group_id, cluster_num)) )\n",
    "\n",
    "                for index, tmp_series in phyla_dists['df'].iloc[1:, :].iterrows():\n",
    "                    if tmp_series.phylum in sampled_phyla:\n",
    "                        regular_connections.append( (ref_phylum,\n",
    "                                                         tmp_series.phylum,\n",
    "                                                         tmp_series['median'], \n",
    "                                                         '%s#%i' % (group_id, cluster_num)) )\n",
    "\n",
    "            else:\n",
    "                for index, tmp_series in phyla_dists['df'].iterrows():\n",
    "                    if tmp_series.phylum in sampled_phyla:\n",
    "                        regular_connections.append( (ref_phylum,\n",
    "                                                         tmp_series.phylum,\n",
    "                                                         tmp_series['median'], \n",
    "                                                         '%s#%i' % (group_id, cluster_num)) )\n",
    "\n",
    "significant_df = pd.DataFrame(data=significant_connections, columns=['source', 'target', 'distance', 'group'])\n",
    "regular_df     = pd.DataFrame(data=regular_connections,     columns=['source', 'target', 'distance', 'group'])\n",
    "\n",
    "significant_df.dropna(how='any', inplace=True)\n",
    "regular_df.dropna(    how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# iqtree\n",
    "#\n",
    "\n",
    "def assess_transfers_between_phyla(related_phyla):\n",
    "# related_phyla = (1090, 1117)\n",
    "\n",
    "    candidates    = set(significant_df.query('source==\"%i\" and target==\"%i\"' % related_phyla).group.values).union(\n",
    "                        significant_df.query('target==\"%i\" and source==\"%i\"' % related_phyla).group.values\n",
    "                    )\n",
    "    descriptions  = {f'from {related_phyla[0]} to {related_phyla[1]}': set(),\n",
    "                     f'from {related_phyla[1]} to {related_phyla[0]}': set(),\n",
    "                      'sisters':                                       set(),\n",
    "                      'no clear relationship between phyla':           set()}\n",
    "\n",
    "    for candidate in candidates:\n",
    "\n",
    "        group_id, cluster_num = candidate.split('#')\n",
    "\n",
    "        if os.path.isfile('candidates/iqtree/%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                              cluster_num)):\n",
    "            with cd('candidates/iqtree/'):\n",
    "                #\n",
    "                # we need the original tree cause mad removes support values, so we just transfer root positions\n",
    "                try:\n",
    "                    tmp_tree   = match_rooting(ete3.Tree('%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                                           cluster_num),\n",
    "                                                         format=1),\n",
    "                                               ete3.Tree('%s-cluster%s.treefile'        % (group_id, \n",
    "                                                                                           cluster_num),\n",
    "                                                         format=1))\n",
    "                except ete3.parser.newick.NewickError:\n",
    "                    continue\n",
    "\n",
    "        print(candidate)\n",
    "\n",
    "        #\n",
    "        # extract taxIDs to subsample taxonomy tables\n",
    "        taxids = {}\n",
    "        for leaf in tmp_tree.get_leaf_names():\n",
    "            #\n",
    "            # leaf names are composed by <taxid>.<locus_tag>\n",
    "            #   ps: locus_tag may also have \".\" within it\n",
    "            tmp_taxid = int(leaf.split('.')[0])\n",
    "\n",
    "            if tmp_taxid not in taxids:\n",
    "                taxids[tmp_taxid] = []\n",
    "            taxids[tmp_taxid].append(leaf)\n",
    "\n",
    "        #\n",
    "        # select taxIDs from each assessed phylum...\n",
    "        phylum1_taxonomy = eggNOG_taxonomy.loc[taxids].query('phylum==@related_phyla[0]')\n",
    "        phylum2_taxonomy = eggNOG_taxonomy.loc[taxids].query('phylum==@related_phyla[1]')\n",
    "\n",
    "        #\n",
    "        # ... and their respect leaves\n",
    "        phylum1_leaves = set()\n",
    "        for taxid in phylum1_taxonomy.index:\n",
    "            phylum1_leaves.update(taxids[taxid])\n",
    "\n",
    "        phylum2_leaves = set()\n",
    "        for taxid in phylum2_taxonomy.index:\n",
    "            phylum2_leaves.update(taxids[taxid])\n",
    "        \n",
    "        all_leaves = phylum1_leaves.union(phylum2_leaves)\n",
    "\n",
    "        #\n",
    "        # as tree traversing through ete3 isn't very efficient, and doesn't scalate very well,\n",
    "        #   we create an iGraph dag for more effient traversing\n",
    "        dag  = tree_to_dag_bb_and_alrt(tmp_tree)          # we need a directed version...\n",
    "        udag = dag.as_undirected(mode='each') # ... and an undirected one for different processes\n",
    "\n",
    "        #\n",
    "        # placeholders where we will add monophyletic clades for each phylum\n",
    "        phylum1_clades = set() \n",
    "        phylum2_clades = set()\n",
    "\n",
    "        ignored_nodes  = [] # descendants of monophyletic nodes should be ignored once their\n",
    "                            #   ancestors have been stored.\n",
    "\n",
    "        #\n",
    "        # traverse through internal nodes\n",
    "        for node in dag.vs:\n",
    "            if node.index in ignored_nodes:\n",
    "                continue\n",
    "\n",
    "            node_leaves = get_leaf_names(node)\n",
    "\n",
    "            if all_leaves.isdisjoint(node_leaves):\n",
    "                ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "            #\n",
    "            # if there aren't leaves from other phyla within this node it is monophyletic\n",
    "            if phylum1_leaves.intersection(node_leaves) and phylum1_leaves.issuperset(node_leaves):\n",
    "                phylum1_clades.add(node.index)\n",
    "                ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "            elif phylum2_leaves.intersection(node_leaves) and phylum2_leaves.issuperset(node_leaves):\n",
    "                phylum2_clades.add(node.index)\n",
    "                ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "        #\n",
    "        # now we add some flexibility to the monophyly of nodes for three reasons:\n",
    "        #   1) donor nodes within gene trees will never be monophyletic since the recipient\n",
    "        #      must be nested within it.\n",
    "        #   2) if there are other transfers from the donor and/or recipient phyla to a 3rd one\n",
    "        #      we still want to capture it.\n",
    "        #   3) good ol' phylogenetic uncertainty\n",
    "        phylum1_clades = merge_polyphyletic_clades(phylum1_clades, udag)\n",
    "        phylum2_clades = merge_polyphyletic_clades(phylum2_clades, udag)\n",
    "\n",
    "        #\n",
    "        # flag if we can identify relations between phyla:\n",
    "        #   1 nested within 2\n",
    "        #   2 nested within 1\n",
    "        #   1 and 2 are sisters\n",
    "        #\n",
    "        # if no relation is identified, leave as false\n",
    "        phyla_relationship_flag = 0\n",
    "\n",
    "        for clade1, clade2 in itertools.product(phylum1_clades, phylum2_clades):\n",
    "\n",
    "            #\n",
    "            # capture ancestors of clade1 by querying nodes between itself and the root node\n",
    "            clade1_ancestors = udag.vs[clade1].get_shortest_paths(udag.vs[0])[0][1:]\n",
    "            #\n",
    "            # if clade2 within clade1 ancestors it means that clade1 is nested within clade2\n",
    "            #   evidence of transfer from clade2 -> clade1\n",
    "            if clade2 in clade1_ancestors:\n",
    "                well_supported = False\n",
    "                for intermediary in dag.vs[clade2].get_shortest_paths(dag.vs[clade1])[0][:-1]:\n",
    "                    alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "                    ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "\n",
    "                    if alrt >= 80 and ufboot >= 95:\n",
    "                        well_supported = True\n",
    "                        break\n",
    "\n",
    "                if not well_supported:\n",
    "                    continue\n",
    "                descriptions[f'from {related_phyla[1]} to {related_phyla[0]}'].add(candidate)\n",
    "                phyla_relationship_flag = 1\n",
    "                continue\n",
    "\n",
    "            #\n",
    "            # if clade1 within clade2 ancestors it means that clade2 is nested within clade1\n",
    "            #   evidence of transfer from clade1 -> clade2\n",
    "            clade2_ancestors = udag.vs[clade2].get_shortest_paths(udag.vs[0])[0][1:]\n",
    "            if clade1 in clade2_ancestors:\n",
    "                well_supported = False\n",
    "                for intermediary in dag.vs[clade1].get_shortest_paths(dag.vs[clade2])[0][:-1]:\n",
    "                    alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "                    ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "\n",
    "                    if alrt >= 80 and ufboot >= 95:\n",
    "                        well_supported = True\n",
    "                        break\n",
    "\n",
    "                if not well_supported:\n",
    "                    continue\n",
    "                descriptions[f'from {related_phyla[0]} to {related_phyla[1]}'].add(candidate)\n",
    "                phyla_relationship_flag = 1\n",
    "                continue\n",
    "\n",
    "            #\n",
    "            # if clade1 and clade2 are have the same parent noe it means they are sisters\n",
    "            #   evidence of hgt, but information about directionality\n",
    "            if clade1_ancestors[0] == clade2_ancestors[0]:\n",
    "#                 if dag.vs[clade1].predecessors()[0].index:\n",
    "#                     support = dag.vs[clade1].predecessors()[0].in_edges()[0]['support']\n",
    "#                     print('%i and %i are sisters              (%s)' % (related_phyla[0], related_phyla[1], candidate), support)\n",
    "                descriptions['sisters'].add(candidate)\n",
    "#                 else:\n",
    "#                     print('%i and %i are sisters              (%s)' % (related_phyla[0], related_phyla[1], candidate), 'root')\n",
    "                phyla_relationship_flag = 1\n",
    "                continue\n",
    "\n",
    "    #     with cd('candidates/'):\n",
    "    #         with open('%s-cluster%s.figTree' % (group_id, cluster_num), 'w') as out:\n",
    "    #             out.write(visualize_reconstruct_candidate(tmp_tree))\n",
    "\n",
    "        #\n",
    "        # if the flag still is False, we couldn't identify an relationship between phyla\n",
    "        if not phyla_relationship_flag:\n",
    "            descriptions['no clear relationship between phyla'].add(candidate)\n",
    "\n",
    "    return(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            well_supported = False\n",
    "            for intermediary in dag.vs[clade1].get_shortest_paths(dag.vs[clade2])[0][:-1]:\n",
    "                alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "                ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "\n",
    "                if alrt >= 80 and ufboot >= 95:\n",
    "                    well_supported = True\n",
    "                    break\n",
    "\n",
    "            if not well_supported:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COG2452#1\n",
      "COG3046#1\n",
      "COG2896#1\n",
      "COG4665#4\n",
      "COG1075#1\n",
      "COG4663#1\n",
      "COG0612#4\n",
      "COG0637#4\n",
      "2Z87P#0\n",
      "COG0857#0\n",
      "COG0720#3\n",
      "COG1666#2\n",
      "COG2324#4\n",
      "COG0115#2\n",
      "COG1770#1\n",
      "COG0345#1\n",
      "COG3281#3\n",
      "COG0001#4\n",
      "COG0554#3\n",
      "COG4118#7\n",
      "COG3259#2\n",
      "COG1300#1\n",
      "COG1704#1\n",
      "COG1186#2\n",
      "COG1801#4\n",
      "COG2981#4\n",
      "COG3544#2\n",
      "COG0275#0\n",
      "COG4467#0\n",
      "COG0725#2\n",
      "COG3429#0\n",
      "COG2848#0\n",
      "COG2343#0\n",
      "2Z8NV#0\n",
      "COG4978#0\n",
      "COG5493#2\n",
      "COG1517#2\n",
      "COG0783#3\n",
      "COG0499#0\n",
      "COG1894#0\n",
      "COG0310#4\n",
      "COG1086#8\n",
      "COG0354#0\n",
      "COG0258#0\n",
      "COG1528#1\n",
      "COG1785#0\n",
      "COG1350#1\n",
      "COG1351#7\n",
      "COG0828#0\n",
      "COG5000#0\n",
      "COG0167#0\n",
      "COG1941#3\n",
      "COG3379#4\n",
      "COG1905#1\n",
      "COG0310#1\n",
      "COG0049#2\n",
      "COG1304#5\n",
      "COG0769#4\n",
      "COG1353#5\n",
      "COG1336#1\n",
      "COG1177#0\n",
      "COG1554#0\n",
      "COG5635#3\n",
      "COG2326#1\n",
      "COG5207#0\n",
      "COG1314#5\n",
      "COG0461#2\n"
     ]
    }
   ],
   "source": [
    "# descriptions = []\n",
    "# for phylum_pair in itertools.combinations(sampled_phyla, 2):\n",
    "#     if 1224 in phylum_pair:\n",
    "#         continue\n",
    "    \n",
    "#     print(phylum_pair)\n",
    "#     descriptions[phylum_pair] = assess_transfers_between_phyla(phylum_pair)\n",
    "    \n",
    "descriptions = assess_transfers_between_phyla((200795, 1117))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from 200795 to 1117 0\n",
      "from 1117 to 200795 0\n",
      "sisters 0\n",
      "no clear relationship between phyla 0\n"
     ]
    }
   ],
   "source": [
    "for key, value in descriptions.items():\n",
    "    print(key, len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_dag_bb_and_alrt(tree):\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        node.add_feature('alrt', 0.0)\n",
    "        node.add_feature('ufboot', 0.0)\n",
    "\n",
    "        if not node.is_leaf():\n",
    "            support_regex = re.match('^(\\d+(?:\\.\\d+)?)\\/(\\d+(?:\\.\\d+)?)$', node.name)\n",
    "            if support_regex:\n",
    "                node.alrt = float(support_regex.group(1))\n",
    "                node.ufboot = float(support_regex.group(2))\n",
    "            node.name     = 'node_%i' % count\n",
    "\n",
    "    edges = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                edges.append((node.name,\n",
    "                              child.name,\n",
    "                              child.dist,\n",
    "                              child.alrt,\n",
    "                              child.ufboot))\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges     =tuple(edges), \n",
    "                              directed  =True,\n",
    "                              edge_attrs=['weight', 'alrt', 'ufboot']\n",
    "                             )\n",
    "    dag.vs['is_leaf'] = [False if name.startswith('node_') else True\n",
    "                         for name in dag.vs['name']]\n",
    "    return(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_phyla = (200795, 1117)\n",
    "descriptions  = {f'from {related_phyla[0]} to {related_phyla[1]}': set(),\n",
    "                 f'from {related_phyla[1]} to {related_phyla[0]}': set(),\n",
    "                  'sisters':                                       set(),\n",
    "                  'no clear relationship between phyla':           set()}\n",
    "candidates    = set(significant_df.query('source==\"%i\" and target==\"%i\"' % related_phyla).group.values).union(\n",
    "                    significant_df.query('target==\"%i\" and source==\"%i\"' % related_phyla).group.values\n",
    "                )\n",
    "\n",
    "for candidate in candidates:\n",
    "\n",
    "    group_id, cluster_num = candidate.split('#')\n",
    "\n",
    "    if os.path.isfile('candidates/iqtree/%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                          cluster_num)):\n",
    "        with cd('candidates/iqtree/'):\n",
    "            #\n",
    "            # we need the original tree cause mad removes support values, so we just transfer root positions\n",
    "            try:\n",
    "                tmp_tree   = match_rooting(ete3.Tree('%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                                       cluster_num),\n",
    "                                                     format=1),\n",
    "                                           ete3.Tree('%s-cluster%s.treefile'        % (group_id, \n",
    "                                                                                       cluster_num),\n",
    "                                                     format=1))\n",
    "            except ete3.parser.newick.NewickError:\n",
    "                continue\n",
    "    if os.path.isfile('candidates/missing_iqtree/%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                                  cluster_num)):\n",
    "        with cd('candidates/missing_iqtree/'):\n",
    "            #\n",
    "            # we need the original tree cause mad removes support values, so we just transfer root positions\n",
    "            try:\n",
    "                tmp_tree   = match_rooting(ete3.Tree('%s-cluster%s.treefile.rooted' % (group_id, \n",
    "                                                                                       cluster_num),\n",
    "                                                     format=1),\n",
    "                                           ete3.Tree('%s-cluster%s.treefile'        % (group_id, \n",
    "                                                                                       cluster_num),\n",
    "                                                     format=1))\n",
    "            except ete3.parser.newick.NewickError:\n",
    "                continue\n",
    "\n",
    "    #\n",
    "    # extract taxIDs to subsample taxonomy tables\n",
    "    taxids = {}\n",
    "    for leaf in tmp_tree.get_leaf_names():\n",
    "        #\n",
    "        # leaf names are composed by <taxid>.<locus_tag>\n",
    "        #   ps: locus_tag may also have \".\" within it\n",
    "        tmp_taxid = int(leaf.split('.')[0])\n",
    "\n",
    "        if tmp_taxid not in taxids:\n",
    "            taxids[tmp_taxid] = []\n",
    "        taxids[tmp_taxid].append(leaf)\n",
    "\n",
    "    #\n",
    "    # select taxIDs from each assessed phylum...\n",
    "    phylum1_taxonomy = eggNOG_taxonomy.loc[taxids].query('phylum==@related_phyla[0]')\n",
    "    phylum2_taxonomy = eggNOG_taxonomy.loc[taxids].query('phylum==@related_phyla[1]')\n",
    "\n",
    "    #\n",
    "    # ... and their respect leaves\n",
    "    phylum1_leaves = set()\n",
    "    for taxid in phylum1_taxonomy.index:\n",
    "        phylum1_leaves.update(taxids[taxid])\n",
    "\n",
    "    phylum2_leaves = set()\n",
    "    for taxid in phylum2_taxonomy.index:\n",
    "        phylum2_leaves.update(taxids[taxid])\n",
    "\n",
    "    all_leaves = phylum1_leaves.union(phylum2_leaves)\n",
    "\n",
    "    #\n",
    "    # as tree traversing through ete3 isn't very efficient, and doesn't scalate very well,\n",
    "    #   we create an iGraph dag for more effient traversing\n",
    "    dag  = tree_to_dag_bb_and_alrt(tmp_tree)          # we need a directed version...\n",
    "    udag = dag.as_undirected(mode='each') # ... and an undirected one for different processes\n",
    "\n",
    "    #\n",
    "    # placeholders where we will add monophyletic clades for each phylum\n",
    "    phylum1_clades = set() \n",
    "    phylum2_clades = set()\n",
    "\n",
    "    ignored_nodes  = [] # descendants of monophyletic nodes should be ignored once their\n",
    "                        #   ancestors have been stored.\n",
    "\n",
    "    #\n",
    "    # traverse through internal nodes\n",
    "    for node in dag.vs:\n",
    "        if node.index in ignored_nodes:\n",
    "            continue\n",
    "\n",
    "        node_leaves = get_leaf_names(node)\n",
    "\n",
    "        if all_leaves.isdisjoint(node_leaves):\n",
    "            ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "        #\n",
    "        # if there aren't leaves from other phyla within this node it is monophyletic\n",
    "        if phylum1_leaves.intersection(node_leaves) and phylum1_leaves.issuperset(node_leaves):\n",
    "            phylum1_clades.add(node.index)\n",
    "            ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "        elif phylum2_leaves.intersection(node_leaves) and phylum2_leaves.issuperset(node_leaves):\n",
    "            phylum2_clades.add(node.index)\n",
    "            ignored_nodes.extend(get_descendant_indices(node, leaves=True))\n",
    "\n",
    "    #\n",
    "    # now we add some flexibility to the monophyly of nodes for three reasons:\n",
    "    #   1) donor nodes within gene trees will never be monophyletic since the recipient\n",
    "    #      must be nested within it.\n",
    "    #   2) if there are other transfers from the donor and/or recipient phyla to a 3rd one\n",
    "    #      we still want to capture it.\n",
    "    #   3) good ol' phylogenetic uncertainty\n",
    "    phylum1_clades = merge_polyphyletic_clades(phylum1_clades, udag)\n",
    "    phylum2_clades = merge_polyphyletic_clades(phylum2_clades, udag)\n",
    "\n",
    "    #\n",
    "    # flag if we can identify relations between phyla:\n",
    "    #   1 nested within 2\n",
    "    #   2 nested within 1\n",
    "    #   1 and 2 are sisters\n",
    "    #\n",
    "    # if no relation is identified, leave as false\n",
    "    phyla_relationship_flag = 0\n",
    "\n",
    "    for clade1, clade2 in itertools.product(phylum1_clades, phylum2_clades):\n",
    "\n",
    "        #\n",
    "        # capture ancestors of clade1 by querying nodes between itself and the root node\n",
    "        clade1_ancestors = udag.vs[clade1].get_shortest_paths(udag.vs[0])[0][1:]\n",
    "        #\n",
    "        # if clade2 within clade1 ancestors it means that clade1 is nested within clade2\n",
    "        #   evidence of transfer from clade2 -> clade1\n",
    "        if clade2 in clade1_ancestors:\n",
    "            \n",
    "            well_supported = False\n",
    "            for intermediary in dag.vs[clade2].get_shortest_paths(dag.vs[clade1])[0][:-1]:\n",
    "                alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "                ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "\n",
    "                if alrt >= 80 and ufboot >= 95:\n",
    "                    well_supported = True\n",
    "                    break\n",
    "\n",
    "            if not well_supported:\n",
    "                continue\n",
    "\n",
    "            descriptions[f'from {related_phyla[1]} to {related_phyla[0]}'].add(candidate)\n",
    "            phyla_relationship_flag = 1\n",
    "            break\n",
    "\n",
    "        #\n",
    "        # if clade1 within clade2 ancestors it means that clade2 is nested within clade1\n",
    "        #   evidence of transfer from clade1 -> clade2\n",
    "        clade2_ancestors = udag.vs[clade2].get_shortest_paths(udag.vs[0])[0][1:]\n",
    "        if clade1 in clade2_ancestors:\n",
    "            \n",
    "            well_supported = False\n",
    "            for intermediary in dag.vs[clade1].get_shortest_paths(dag.vs[clade2])[0][:-1]:\n",
    "                alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "                ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "\n",
    "                if alrt >= 80 and ufboot >= 95:\n",
    "                    well_supported = True\n",
    "                    break\n",
    "\n",
    "            if not well_supported:\n",
    "                continue\n",
    "\n",
    "            descriptions[f'from {related_phyla[0]} to {related_phyla[1]}'].add(candidate)\n",
    "            phyla_relationship_flag = 1\n",
    "            break\n",
    "\n",
    "        #\n",
    "        # if clade1 and clade2 are have the same parent noe it means they are sisters\n",
    "        #   evidence of hgt, but information about directionality\n",
    "        if clade1_ancestors[0] == clade2_ancestors[0]:\n",
    "#                 if dag.vs[clade1].predecessors()[0].index:\n",
    "#                     support = dag.vs[clade1].predecessors()[0].in_edges()[0]['support']\n",
    "#                     print('%i and %i are sisters              (%s)' % (related_phyla[0], related_phyla[1], candidate), support)\n",
    "            descriptions['sisters'].add(candidate)\n",
    "#                 else:\n",
    "#                     print('%i and %i are sisters              (%s)' % (related_phyla[0], related_phyla[1], candidate), 'root')\n",
    "            phyla_relationship_flag = 1\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from 200795 to 1117': {'COG0049#2',\n",
       "  'COG0345#1',\n",
       "  'COG0354#0',\n",
       "  'COG0554#3',\n",
       "  'COG0637#4',\n",
       "  'COG1177#0',\n",
       "  'COG1304#5',\n",
       "  'COG1351#7',\n",
       "  'COG1554#0',\n",
       "  'COG2452#1',\n",
       "  'COG4978#0'},\n",
       " 'from 1117 to 200795': {'COG0115#2',\n",
       "  'COG1941#3',\n",
       "  'COG2343#0',\n",
       "  'COG2981#4',\n",
       "  'COG4467#0'},\n",
       " 'sisters': {'COG0167#0',\n",
       "  'COG0310#4',\n",
       "  'COG1894#0',\n",
       "  'COG4978#0',\n",
       "  'COG5000#0',\n",
       "  'COG5493#2'},\n",
       " 'no clear relationship between phyla': set()}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129, 161, 197, 245, 301]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.vs[129].get_shortest_paths(dag.vs[355])[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.3 84.0\n"
     ]
    }
   ],
   "source": [
    "well_supported = False\n",
    "for intermediary in dag.vs[129].get_shortest_paths(dag.vs[355])[0][:-1]:\n",
    "    alrt   = dag.vs[intermediary].in_edges()[0]['alrt'  ]\n",
    "    ufboot = dag.vs[intermediary].in_edges()[0]['ufboot']\n",
    "    \n",
    "    if alrt >= 80 and ufboot >= 95:\n",
    "        well_supported = True\n",
    "        break\n",
    "\n",
    "print(alrt, ufboot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "well_supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nobackup1b/users/thiberio/eggNOG'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_tree.search_nodes(name='node_28')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.vs[355].in_edges()[0]['ufboot'  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('candidates/COG0499#0.iqtree.figTree', 'w') as out:\n",
    "    out.write(visualize_reconstructed_candidate(deepcopy(tmp_tree)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstructed_candidate(tree):\n",
    "\n",
    "    \n",
    "    out = \"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(tree)\n",
    "\n",
    "    count               = 0\n",
    "    internal_node_names = {}\n",
    "    for node in tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid, locus_tag = node.name.split('.')\n",
    "            try:\n",
    "                lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(taxid)).items()}\n",
    "            except ValueError:\n",
    "                out += '\\t%s\\n' %(node.name)\n",
    "                continue\n",
    "            else:\n",
    "                lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out += '\\t%s ' %(node.name)\n",
    "            comment = []\n",
    "            for rank in ['class', 'phylum', 'order', 'family', 'species']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            if 'tax_phylum=\"Cyanobacteria\"' in comment:\n",
    "                comment.append('!color=#00ff00')\n",
    "            elif 'tax_phylum=\"Chloroflexi\"' in comment:\n",
    "                comment.append('!color=#ff0000')\n",
    "                            \n",
    "            out += '[&%s]\\n' %' '.join(comment)\n",
    "\n",
    "        else:\n",
    "            internal_node_names['node_%i_' % count] = '[&node_name=%s,ufboot=%.2f, alrt=%.2f]' % (deepcopy(node.name), node.ufboot, node.alrt)\n",
    "            node.name = 'node_%i_' % count\n",
    "            count += 1\n",
    "\n",
    "    newick_text = tree.write(format=1)\n",
    "    for tmp_name, full_name in internal_node_names.items():\n",
    "        newick_text = newick_text.replace(tmp_name, full_name)\n",
    "        \n",
    "    out += ';\\nend;\\n'\n",
    "    out += 'begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text\n",
    "\n",
    "    return(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
