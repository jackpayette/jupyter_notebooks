{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_polyphyletic_clades(clades, udag):\n",
    "    clades = deepcopy(clades)\n",
    "    \n",
    "    merge_clades_threshold = ceil(len(udag.vs.select(is_leaf=False)) * 0.01)\n",
    "    while True:\n",
    "\n",
    "        should_merge = False\n",
    "        for clade1, clade2 in itertools.combinations(clades, 2):\n",
    "#             clade1_index = int(clade1.split('_')[1])\n",
    "#             clade2_index = int(clade2.split('_')[1])\n",
    "            \n",
    "            node1 = udag.vs[clade1]\n",
    "            node2 = udag.vs[clade2]\n",
    "            \n",
    "            node1_ancestors = node1.get_shortest_paths(udag.vs[0])[0]\n",
    "            node2_ancestors = node2.get_shortest_paths(udag.vs[0])[0]\n",
    "\n",
    "            bipartitions_in_between = node1.shortest_paths(node2)[0][0] - 1\n",
    "            if bipartitions_in_between <= merge_clades_threshold or \\\n",
    "               clade1 in node2_ancestors or \\\n",
    "               clade2 in node1_ancestors:\n",
    "                \n",
    "                node1_ancestors = node1.get_shortest_paths(udag.vs[0])[0]\n",
    "                node2_ancestors = node2.get_shortest_paths(udag.vs[0])[0]\n",
    "\n",
    "                common_ancestors = set(node1_ancestors).intersection(node2_ancestors)\n",
    "                lca = sorted(common_ancestors)[-1]\n",
    "                if lca == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    should_merge = True\n",
    "                    break\n",
    "\n",
    "        if should_merge:\n",
    "            clades.remove(clade1)\n",
    "            clades.remove(clade2)\n",
    "            clades.add(lca)\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return(clades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leaf_names(node):\n",
    "    leaf_names = []\n",
    "    \n",
    "    if node['is_leaf']:\n",
    "        leaf_names.append(node['name'])\n",
    "        \n",
    "    for successor in node.successors():\n",
    "        if successor['is_leaf']:\n",
    "            leaf_names.append(successor['name'])\n",
    "        else:\n",
    "            leaf_names.extend(get_leaf_names(successor))\n",
    "    \n",
    "    return(leaf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descendant_names(node, leaves=False):\n",
    "    descendant_names = []\n",
    "    \n",
    "    for successor in node.successors():\n",
    "        if successor['is_leaf']:\n",
    "            if leaves:\n",
    "                descendant_names.append(successor['name'])\n",
    "\n",
    "        else:\n",
    "            descendant_names.append(successor['name'])\n",
    "            descendant_names.extend(get_descendant_names(successor, leaves))\n",
    "    \n",
    "    return(descendant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descendant_indices(node, leaves=False):\n",
    "    descendant_names = []\n",
    "    \n",
    "    for successor in node.successors():\n",
    "        if successor['is_leaf']:\n",
    "            if leaves:\n",
    "                descendant_names.append(successor.index)\n",
    "\n",
    "        else:\n",
    "            descendant_names.append(successor.index)\n",
    "            descendant_names.extend(get_descendant_indices(successor, leaves))\n",
    "    \n",
    "    return(descendant_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_dag(tree):\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if not node.is_leaf():\n",
    "            node.name = 'node_%i' % count\n",
    "\n",
    "    edges = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                edges.append((node.name,\n",
    "                              child.name,\n",
    "                              child.dist,\n",
    "                              child.support))\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges     =tuple(edges), \n",
    "                              directed  =True,\n",
    "                              edge_attrs=['weight', 'support']\n",
    "                             )\n",
    "    dag.vs['is_leaf'] = [False if name.startswith('node_') else True\n",
    "                         for name in dag.vs['name']]\n",
    "    return(dag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances_from_dag(dag, leaf_names):\n",
    "    bipartitions_in_between = np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                          target=leaf_names, \n",
    "                                                          weights=None)) - 1\n",
    "    patristic_distances     = np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                          target=leaf_names, \n",
    "                                                          weights='weight'))\n",
    "                                       \n",
    "    np.fill_diagonal(bipartitions_in_between, 0.0)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =patristic_distances**bipartitions_in_between\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_taxa_graph(dist_matrix):\n",
    "    triu_indices       = np.triu_indices_from(dist_matrix, k=1)\n",
    "    \n",
    "    edge_list                 = pd.DataFrame()\n",
    "    edge_list['sequence1']    = dist_matrix.index[triu_indices[0]]\n",
    "    edge_list['sequence2']    = dist_matrix.index[triu_indices[1]]\n",
    "    edge_list['distance']     = dist_matrix.values[triu_indices]\n",
    "    edge_list['inverse_dist'] = np.e**np.negative(edge_list.distance)\n",
    "\n",
    "\n",
    "    graph  = ig.Graph.TupleList(edges=edge_list[['sequence1', \n",
    "                                                 'sequence2', \n",
    "                                                 'inverse_dist']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights =True)\n",
    "    \n",
    "    return(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_rooting(reference_root, tree_to_root):\n",
    "    tmp_tree = tree_to_root.copy()\n",
    "    \n",
    "    for node in sorted( reference_root.children, key=len ):\n",
    "        if node.is_leaf():\n",
    "            leaf = tmp_tree.get_leaves_by_name(node.name)[0]\n",
    "            tmp_tree.set_outgroup(leaf)\n",
    "            return tmp_tree\n",
    "        else:\n",
    "            is_it_monophyletic, clade_type, fucking_up = tmp_tree.check_monophyly(\n",
    "                node.get_leaf_names(), \n",
    "                'name',\n",
    "                unrooted=False\n",
    "            )\n",
    "            if is_it_monophyletic:\n",
    "                equivalent = tmp_tree.get_common_ancestor(node.get_leaf_names())\n",
    "                tmp_tree.set_outgroup(equivalent)\n",
    "            else:\n",
    "                tmp_tree.set_outgroup(fucking_up.pop())\n",
    "                equivalent = tmp_tree.get_common_ancestor(node.get_leaf_names())\n",
    "                tmp_tree.set_outgroup(equivalent)\n",
    "\n",
    "            return tmp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances(group_id):\n",
    "    \n",
    "    tree = ete3.Tree(working_trees.loc[group_id, 'tree'])\n",
    "\n",
    "    leaf_names = []\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            leaf_names.append(node.name)\n",
    "        else:\n",
    "            node.name = 'node_%i' % count\n",
    "    leaf_names = np.array(leaf_names)\n",
    "\n",
    "    nodes         = []\n",
    "    children      = []\n",
    "    branch_length = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                nodes.append(         node.name)\n",
    "                children.append(     child.name)\n",
    "                branch_length.append(child.dist)\n",
    "\n",
    "    branch_length_df                  = pd.DataFrame()\n",
    "    branch_length_df['node']          = nodes\n",
    "    branch_length_df['child']         = children\n",
    "    branch_length_df['branch_length'] = branch_length\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges=branch_length_df[['node', \n",
    "                                                      'child', \n",
    "                                                      'branch_length']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights=True)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                                   target=leaf_names, \n",
    "                                                                   weights='weight'))\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairwise_distances_from_tree(tree):\n",
    "    \n",
    "    leaf_names = []\n",
    "    for count, node in enumerate(tree.traverse()):\n",
    "        if node.is_leaf():\n",
    "            leaf_names.append(node.name)\n",
    "        else:\n",
    "            node.name = 'node_%i' % count\n",
    "    leaf_names = np.array(leaf_names)\n",
    "\n",
    "    nodes         = []\n",
    "    children      = []\n",
    "    branch_length = []\n",
    "    for node in tree.traverse():\n",
    "        if not node.is_leaf():\n",
    "            for child in node.get_children():\n",
    "                nodes.append(         node.name)\n",
    "                children.append(     child.name)\n",
    "                branch_length.append(child.dist)\n",
    "\n",
    "    branch_length_df                  = pd.DataFrame()\n",
    "    branch_length_df['node']          = nodes\n",
    "    branch_length_df['child']         = children\n",
    "    branch_length_df['branch_length'] = branch_length\n",
    "\n",
    "    dag  = ig.Graph.TupleList(edges=branch_length_df[['node', \n",
    "                                                      'child', \n",
    "                                                      'branch_length']].itertuples(index=False), \n",
    "                                directed=False, \n",
    "                                weights=True)\n",
    "    \n",
    "    dist_matrix = pd.DataFrame(index  =leaf_names, \n",
    "                               columns=leaf_names, \n",
    "                               data   =np.array(dag.shortest_paths(source=leaf_names, \n",
    "                                                                   target=leaf_names, \n",
    "                                                                   weights='weight'))\n",
    "                              )\n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cluster(clusterID):\n",
    "    group_id, cluster_num = clusterID.split('#')\n",
    "    dist_matrix = get_pairwise_distances(group_id)\n",
    "\n",
    "    taxids = [int(leaf.split('.')[0]) for leaf in dist_matrix.index]\n",
    "    phyla  = eggNOG_taxonomy.loc[taxids, 'phylum'].values.astype(int)\n",
    "\n",
    "    graph  = create_taxa_graph(dist_matrix)\n",
    "\n",
    "    random.seed(12345)\n",
    "    clusters = graph.community_multilevel(weights='weight')\n",
    "\n",
    "    node_data = pd.DataFrame(columns=['name', 'phylum', 'cluster'],\n",
    "                             data   =zip(dist_matrix.index, \n",
    "                                         phyla, \n",
    "                                         clusters.membership)\n",
    "                            )\n",
    "    \n",
    "    cluster_seqs = node_data.loc[node_data.cluster==int(cluster_num), 'name'].values\n",
    "    \n",
    "    if not os.path.isfile('alignments/%s' % group_id):\n",
    "        subprocess.call(['curl', \n",
    "                         'http://eggnogapi5.embl.de/nog_data/text/raw_alg/%s' % group_id,\n",
    "                         '--output', 'alignments/%s.gz' % group_id])\n",
    "        \n",
    "        if subprocess.call(['gzip',\n",
    "                            '-d',\n",
    "                            'alignments/%s.gz' % group_id]):\n",
    "            subprocess.call(['cp',\n",
    "                             'alignments/%s.gz' % group_id, \n",
    "                             'alignments/%s' % group_id])\n",
    "    \n",
    "    with open('alignments/%s' % group_id) as fasta_handle,\\\n",
    "         open('alignments/%s-cluster%s.faa' % (group_id, cluster_num), 'w') as out:\n",
    "        \n",
    "        fasta = fasta_handle.read()\n",
    "        if not fasta.startswith('>'):\n",
    "            return(False)\n",
    "        \n",
    "        for entry in fasta.split('>'):\n",
    "            if entry and entry.split()[0] in cluster_seqs:\n",
    "                out.write('>%s' % entry)\n",
    "    \n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_candidate_for_tree(group_cluster):\n",
    "    cluster_extracted = extract_cluster(group_cluster)\n",
    "    \n",
    "    if not cluster_extracted:\n",
    "        return(False)\n",
    "    \n",
    "    group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "    with open('alignments/%s-cluster%s.aln' % (group_id, cluster_num), 'w') as out:\n",
    "        subprocess.call(['/cm/shared/engaging/mafft/7.245-with-extensions/bin/mafft', \n",
    "                         '--auto', \n",
    "                         '--reorder', \n",
    "                         'alignments/%s-cluster%s.faa' % (group_id, cluster_num)],\n",
    "                        stdout=out)\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_candidate_fastTree(group_cluster):\n",
    "    ready_for_tree = prepare_candidate_for_tree(group_cluster)\n",
    "    \n",
    "    if not ready_for_tree:\n",
    "        return(False)\n",
    "    \n",
    "    group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "    subprocess.call(['/cm/shared/engaging/FastTree/2.1.8/bin/FastTree',\n",
    "                     '-out', 'trees/%s-cluster%s.fastTree' % (group_id, cluster_num),\n",
    "                     '-quiet',\n",
    "                     '-wag',\n",
    "                     '-gamma',\n",
    "                     'alignments/%s-cluster%s.aln' % (group_id, cluster_num)])\n",
    "    \n",
    "    subprocess.call(['/home/thiberio/.conda/envs/py37/bin/python3',\n",
    "                     '/nobackup1b/users/thiberio/mad.py',\n",
    "                     'trees/%s-cluster%s.fastTree' % (group_id, cluster_num),\n",
    "                     '-t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_candidate(group_cluster):\n",
    "    extract_cluster(group_cluster)\n",
    "    \n",
    "    group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "    with open('alignments/%s-cluster%s.aln' % (group_id, cluster_num), 'w') as out:\n",
    "        subprocess.call(['/cm/shared/engaging/mafft/7.245-with-extensions/bin/mafft', \n",
    "                         '--auto', \n",
    "                         '--reorder', \n",
    "                         'alignments/%s-cluster%s.faa' % (group_id, cluster_num)],\n",
    "                        stdout=out)\n",
    "        \n",
    "    subprocess.call(['/cm/shared/engaging/iqtree/1.6.3/bin/iqtree',\n",
    "                     '-m', 'LG+G',\n",
    "                     '-nt', '2',\n",
    "                     '-s', 'alignments/%s-cluster%s.aln' % (group_id, cluster_num),\n",
    "                     '-pre', 'trees/%s-cluster%s' % (group_id, cluster_num),\n",
    "                     '-bb', '1000', \n",
    "                     '-quiet',\n",
    "                     '-safe'])\n",
    "    \n",
    "    subprocess.call(['/home/thiberio/.conda/envs/py37/bin/python3',\n",
    "                     '/nobackup1b/users/thiberio/mad.py',\n",
    "                     'trees/%s-cluster%s.treefile' % (group_id, cluster_num),\n",
    "                     '-t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_reconstruct_candidate(group_cluster):\n",
    "\n",
    "#     group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "#     with cd('trees'):\n",
    "#         tree   = match_rooting(ete3.Tree('%s-cluster%s.treefile.rooted' % (group_id, cluster_num)),\n",
    "#                                ete3.Tree('%s-cluster%s.treefile'        % (group_id, cluster_num)))\n",
    "\n",
    "#     out  = open('%s-cluster%s.figTree' % (group_id, cluster_num), 'w')\n",
    "#     out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(tree))\n",
    "\n",
    "#     for node in tree.traverse():\n",
    "#         if node.is_leaf():\n",
    "#             taxid, locus_tag = node.name.split('.')\n",
    "#             try:\n",
    "#                 lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(taxid)).items()}\n",
    "#             except ValueError:\n",
    "#                 out.write('\\t%s\\n' %(node.name))\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "#             out.write('\\t%s ' %(node.name))\n",
    "#             comment = []\n",
    "#             for rank in ['class', 'phylum', 'order', 'family', 'species']:\n",
    "#                 if rank in lineage:\n",
    "#                     comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "#             out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "#     newick_text = tree.write(format=0)\n",
    "#     out.write(';\\nend;\\n')\n",
    "#     out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "#     out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstructed_candidate(tree):\n",
    "\n",
    "    out = \"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(tree)\n",
    "\n",
    "    count               = 0\n",
    "    internal_node_names = {}\n",
    "    for node in tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid, locus_tag = node.name.split('.')\n",
    "            try:\n",
    "                lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(taxid)).items()}\n",
    "            except ValueError:\n",
    "                out += '\\t%s\\n' %(node.name)\n",
    "                continue\n",
    "            else:\n",
    "                lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out += '\\t%s ' %(node.name)\n",
    "            comment = []\n",
    "            for rank in ['class', 'phylum', 'order', 'family', 'species']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            if 'tax_phylum=\"Cyanobacteria\"' in comment:\n",
    "                comment.append('!color=#00ff00')\n",
    "            elif 'tax_phylum=\"Chlorobi\"' in comment:\n",
    "                comment.append('!color=#ff0000')\n",
    "            out += '[&%s]\\n' %' '.join(comment)\n",
    "\n",
    "        else:\n",
    "            internal_node_names['node_%i_' % count] = '[&node_name=%s,support=%.2f]' % (node.name, node.support)\n",
    "            node.name = 'node_%i_' % count\n",
    "            count += 1\n",
    "\n",
    "    newick_text = tree.write(format=1)\n",
    "    for tmp_name, full_name in internal_node_names.items():\n",
    "        newick_text = newick_text.replace(tmp_name, full_name)\n",
    "        \n",
    "    out += ';\\nend;\\n'\n",
    "    out += 'begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text\n",
    "\n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruct_candidate_fastTree(group_cluster):\n",
    "\n",
    "    group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "    with cd('trees'):\n",
    "        tree   = match_rooting(ete3.Tree('%s-cluster%s.fastTree.rooted' % (group_id, cluster_num)),\n",
    "                               ete3.Tree('%s-cluster%s.fastTree'        % (group_id, cluster_num)))\n",
    "\n",
    "    out  = open('%s-cluster%s.fastFigTree' % (group_id, cluster_num), 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(tree))\n",
    "\n",
    "    for node in tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid, locus_tag = node.name.split('.')\n",
    "            try:\n",
    "                lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(taxid)).items()}\n",
    "            except ValueError:\n",
    "                out.write('\\t%s\\n' %(node.name))\n",
    "                continue\n",
    "            else:\n",
    "                lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out.write('\\t%s ' %(node.name))\n",
    "            comment = []\n",
    "            for rank in ['class', 'phylum', 'order', 'family', 'species']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "    newick_text = tree.write(format=0)\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_candidates(group_cluster):\n",
    "    extract_cluster(group_cluster)\n",
    "    \n",
    "    group_id, cluster_num = group_cluster.split('#')\n",
    "    \n",
    "    with open('alignments/%s-cluster%s.aln' % (group_id, cluster_num), 'w') as out:\n",
    "        subprocess.call(['/cm/shared/engaging/mafft/7.245-with-extensions/bin/mafft', \n",
    "                         '--auto', \n",
    "                         '--reorder', \n",
    "                         'alignments/%s-cluster%s.faa' % (group_id, cluster_num)],\n",
    "                        stdout=out)\n",
    "        \n",
    "    subprocess.call(['/cm/shared/engaging/FastTree/2.1.8/bin/FastTree',\n",
    "                     '-gamma', \n",
    "                     '-wag', \n",
    "                     '-out', 'alignments/%s-cluster%s.tree' % (group_id, cluster_num), \n",
    "                     'alignments/%s-cluster%s.aln' % (group_id, cluster_num)])\n",
    "    \n",
    "    tree = ete3.Tree('alignments/%s-cluster%s.tree' % (group_id, cluster_num), format=0)\n",
    "\n",
    "    out  = open('chlorobi_to_cyano/%s-cluster%s.fastFigTree' % (group_id, cluster_num), 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(tree))\n",
    "\n",
    "    for node in tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid, locus_tag = node.name.split('.')\n",
    "            try:\n",
    "                lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(taxid)).items()}\n",
    "            except ValueError:\n",
    "                out.write('\\t%s\\n' %(node.name))\n",
    "                continue\n",
    "            else:\n",
    "                lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out.write('\\t%s ' %(node.name))\n",
    "            comment = []\n",
    "            for rank in ['class', 'phylum', 'order', 'family', 'species']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "    newick_text = tree.write(format=0)\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "    out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
