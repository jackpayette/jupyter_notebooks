{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.odr              import Model, Data, RealData, ODR\n",
    "from scipy.stats            import linregress\n",
    "from scipy.optimize         import curve_fit\n",
    "from scipy.spatial.distance import squareform\n",
    "from matplotlib             import pyplot as plt\n",
    "from sklearn.linear_model   import HuberRegressor\n",
    "from copy                   import deepcopy\n",
    "from collections            import Counter\n",
    "import numpy   as np\n",
    "import seaborn as sns\n",
    "import pandas  as pd\n",
    "import random\n",
    "import os\n",
    "import subprocess\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Good reads:\n",
    "- https://towardsdatascience.com/total-least-squares-in-comparison-with-ols-and-odr-f050ffc1a86a\n",
    "- https://towardsdatascience.com/linear-regression-in-the-wild-335723a687e8\n",
    "- https://en.wikipedia.org/wiki/Deming_regression\n",
    "- https://en.wikipedia.org/wiki/Total_least_squares\n",
    "- https://stackoverflow.com/questions/44638882/estimate-the-standard-deviation-of-fitted-parameters-in-scipy-odr\n",
    "- https://www.astro.rug.nl/software/kapteyn/kmpfittutorial.html#fitting-data-when-both-variables-have-uncertainties\n",
    "- https://stats.stackexchange.com/a/461968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line(x, slope):\n",
    "    \"\"\"Basic linear regression 'model'\"\"\"\n",
    "    return (slope * x) + 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_weights(x, y, weight_estimation='gm'):\n",
    "    if weight_estimation == 'gm':\n",
    "        slope = np.std(y)/np.std(x)\n",
    "        x_res = abs(x - line(y, \n",
    "                             slope))\n",
    "        y_res = abs(y - line(x, \n",
    "                             slope))\n",
    "\n",
    "    elif weight_estimation == 'huber':\n",
    "        huber_xy  = HuberRegressor(fit_intercept=False).fit(x.reshape(-1, 1), y)\n",
    "        huber_yx  = HuberRegressor(fit_intercept=False).fit(y.reshape(-1, 1), x)\n",
    "\n",
    "        y_res     = abs(y - line(x, \n",
    "                                 huber_xy.coef_))\n",
    "\n",
    "        x_res     = abs(x - line(y, \n",
    "                                 huber_yx.coef_))\n",
    "        \n",
    "    elif weight_estimation == 'ols':\n",
    "        xy_params = curve_fit(line, x, y)\n",
    "        y_res     = abs(y - line(x, \n",
    "                                 xy_params[0]))\n",
    "        \n",
    "        yx_params = curve_fit(line, y, x)\n",
    "        x_res     = abs(x - line(y, \n",
    "                                 yx_params[0]))\n",
    "    else:\n",
    "        raise Exception('weight_estimation must be \"gm\", \"huber\", or \"ols\"')\n",
    "\n",
    "    return(1/abs(x_res), \n",
    "           1/abs(y_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_odr(x, y, x_weights, y_weights):\n",
    "    mod = Model(line)\n",
    "    dat = Data(x, \n",
    "               y, \n",
    "               wd=x_weights, \n",
    "               we=y_weights\n",
    "    )\n",
    "    odr = ODR(dat, \n",
    "              mod,\n",
    "              beta0=[1])\n",
    "    return(odr.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dist_matrix(aln_file=None, iqtree_path='iqtree', num_threads=1):\n",
    "    path     = '/'.join(aln_file.split('/')[:-1])\n",
    "    filename = aln_file.split('/')[-1]\n",
    "    \n",
    "    with cd(path):\n",
    "        \n",
    "        if not os.path.isfile(f'{filename}.mldist'):\n",
    "            subprocess.call([iqtree_path, \n",
    "                             '-s',     filename, \n",
    "                             '-m',     'LG+G', \n",
    "                             '-te',    'BIONJ',\n",
    "                             '-nt',    'AUTO',\n",
    "                             '-ntmax', str(num_threads),\n",
    "                             '-keep-ident', '-safe', '-quiet'])\n",
    "        \n",
    "        dist_matrix = pd.read_csv(f'{filename}.mldist', \n",
    "                                  delim_whitespace = True, \n",
    "                                  skiprows         = 1, \n",
    "                                  header           = None,\n",
    "                                  index_col        = 0)\n",
    "        dist_matrix.columns = dist_matrix.index\n",
    "    \n",
    "    return(dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_matrices(matrix1, matrix2):\n",
    "    \n",
    "    tmp_taxa = []\n",
    "    for index in matrix1.index:\n",
    "        genome, gene = re.search('^(GC[AF]_\\d+(?:\\.\\d)?)[_|](.*)$', index).groups()\n",
    "        tmp_taxa.append([index, genome, gene])\n",
    "\n",
    "    taxa1 = pd.DataFrame(columns=['taxon', 'genome', 'gene'],\n",
    "                         data=tmp_taxa)\n",
    "\n",
    "    tmp_taxa = []\n",
    "    for index in matrix2.index:\n",
    "        genome, gene = re.search('^(GC[AF]_\\d+(?:\\.\\d)?)[_|](.*)$', index).groups()\n",
    "        tmp_taxa.append([index, genome, gene])\n",
    "\n",
    "    taxa2 = pd.DataFrame(columns=['taxon', 'genome', 'gene'],\n",
    "                         data=tmp_taxa)\n",
    "\n",
    "    shared_genomes = np.intersect1d(taxa1.genome.unique(), \n",
    "                                    taxa2.genome.unique())\n",
    "\n",
    "    taxa1 = taxa1[taxa1.genome.isin(shared_genomes)]\n",
    "    taxa2 = taxa2[taxa2.genome.isin(shared_genomes)]\n",
    "\n",
    "    if not taxa1.genome.is_unique or not taxa2.genome.is_unique:\n",
    "        return(None)\n",
    "    \n",
    "        taxa1_frequency = Counter(taxa1.genome) \n",
    "        taxa2_frequency = Counter(taxa2.genome)\n",
    "\n",
    "        for (genome1, genome1_count), \\\n",
    "            (genome2, genome2_count) in zip(taxa1_frequency.items(), \n",
    "                                            taxa2_frequency.items()):\n",
    "\n",
    "            genome_frequency_difference = genome1_count - genome2_count\n",
    "\n",
    "            if genome_frequency_difference > 0:\n",
    "                for _ in range(abs(genome_frequency_difference)):\n",
    "                    taxa2.append(pd.Series([f'{genome}|dummy{_}', \n",
    "                                            genome, \n",
    "                                            f'dummy{_}'], \n",
    "                                           index=['taxon', 'genome', 'gene']), \n",
    "                                 ignore_index=True)\n",
    "\n",
    "            if genome_frequency_difference < 0:\n",
    "                for _ in range(abs(genome_frequency_difference)):\n",
    "                    taxa1.append(pd.Series([f'{genome}|dummy{_}', \n",
    "                                            genome, \n",
    "                                            f'dummy{_}'], \n",
    "                                           index=['taxon', 'genome', 'gene']), \n",
    "                                 ignore_index=True)\n",
    "\n",
    "    taxa1.sort_values('genome', inplace=True)\n",
    "    taxa2.sort_values('genome', inplace=True)\n",
    "    \n",
    "    matrix1 = matrix1.reindex(index  =taxa1.taxon, \n",
    "                              columns=taxa1.taxon, \n",
    "                              copy   =True)\n",
    "    matrix2 = matrix2.reindex(index  =taxa2.taxon, \n",
    "                              columns=taxa2.taxon, \n",
    "                              copy   =True)\n",
    "    \n",
    "    matrix1[matrix1.isna()] = 0.0\n",
    "    matrix2[matrix2.isna()] = 0.0\n",
    "    \n",
    "    return(matrix1, taxa1, matrix2, taxa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_coevolution(matrix1, matrix2, weighted_r2=False):\n",
    "    matrix1, taxa1, matrix2, taxa2 = balance_matrices(matrix1, matrix2)\n",
    "    \n",
    "    condensed1 = squareform(matrix1.values)\n",
    "    condensed2 = squareform(matrix2.values)\n",
    "    \n",
    "    odr_weights = estimate_weights(condensed1, condensed2)\n",
    "    \n",
    "    regression = run_odr(condensed1, \n",
    "                         condensed2, \n",
    "                         *odr_weights)\n",
    "    \n",
    "    mean_x = np.mean(condensed1)\n",
    "    mean_y = np.mean(condensed2)\n",
    "\n",
    "    if weighted_r2:\n",
    "        sse = regression.work[regression.work_ind['wss']]\n",
    "        sst = sum(((condensed1 - mean_x)**2)*odr_weights[0])+\\\n",
    "              sum(((condensed2 - mean_y)**2)*odr_weights[1])\n",
    "    else:\n",
    "        sse = sum(regression.delta**2) + sum(regression.eps**2)\n",
    "        sst = sum((condensed1 - mean_x)**2)+\\\n",
    "              sum((condensed2 - mean_y)**2)\n",
    "\n",
    "    r2 = 1 - sse/sst\n",
    "\n",
    "    return(regression, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: [0.49615544]\n",
      "Beta Std Error: [0.00033644]\n",
      "Beta Covariance: [[1.99398167e-06]]\n",
      "Residual Variance: 0.056766828371899364\n",
      "Inverse Condition #: 1.0\n",
      "Reason(s) for Halting:\n",
      "  Sum of squares convergence\n",
      "\n",
      "R**2 = 0.8947962483462916\n"
     ]
    }
   ],
   "source": [
    "dist1 = run_dist_matrix('/work/clusterEvo/distance_matrices/000284/000284')\n",
    "dist2 = run_dist_matrix('/work/clusterEvo/distance_matrices/000302/000302')\n",
    "\n",
    "regression, r2 = assess_coevolution(dist1, dist2)\n",
    "\n",
    "regression.pprint()\n",
    "print(f'\\nR**2 = {r2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
