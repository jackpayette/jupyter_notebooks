{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ete3\n",
    "import os\n",
    "import re\n",
    "import multiprocessing\n",
    "import pickle as pkl\n",
    "import linecache\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import plotly\n",
    "import plotly.plotly as ptl\n",
    "from plotly import graph_objs as go\n",
    "ptl.sign_in('lthiberiol', 'm15ikp59lt')\n",
    "\n",
    "os.chdir('/work/Alphas_and_Cyanos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cd:\n",
    "    \"\"\"\n",
    "    Context manager for changing the current working directory\n",
    "    \"\"\"\n",
    "    def __init__(self, newPath):\n",
    "        self.newPath = os.path.expanduser(newPath)\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.savedPath = os.getcwd()\n",
    "        os.chdir(self.newPath)\n",
    "\n",
    "    def __exit__(self, etype, value, traceback):\n",
    "        os.chdir(self.savedPath)\n",
    "\n",
    "def rename_branches(reconciliation_file, tree):\n",
    "    branches         = re.findall('^(m\\d+) = LCA\\[(\\S+), (\\S+)\\]:', reconciliation_file, re.M)\n",
    "    duplicated_names = {}\n",
    "    for name, leaf1, leaf2 in branches:\n",
    "        node = tree.get_common_ancestor(leaf1, leaf2)\n",
    "        if node.name:\n",
    "            duplicated_names[name] = node.name\n",
    "            continue\n",
    "        node.name = name\n",
    "    return tree, duplicated_names\n",
    "\n",
    "def root_like( ref_tree, tree2 ):\n",
    "    tree_to_root = tree2.copy()\n",
    "    for node in sorted( ref_tree.children, key=len ):\n",
    "        if node.is_leaf():\n",
    "            leaf = tree_to_root.get_leaves_by_name(node.name)[0]\n",
    "            tree_to_root.set_outgroup(leaf)\n",
    "            break\n",
    "        else:\n",
    "            is_it_monophyletic, clade_type, fucking_up = tree_to_root.check_monophyly(node.get_leaf_names(), 'name', unrooted=False)\n",
    "            if is_it_monophyletic:\n",
    "                equivalent = tree_to_root.get_common_ancestor(node.get_leaf_names())\n",
    "                tree_to_root.set_outgroup(equivalent)\n",
    "            else:\n",
    "                tree_to_root.set_outgroup(fucking_up.pop())\n",
    "                equivalent = tree_to_root.get_common_ancestor(node.get_leaf_names())\n",
    "                tree_to_root.set_outgroup(equivalent)\n",
    "            break\n",
    "\n",
    "    return tree_to_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_aggregated(folder, threshold=0.9, leaves_allowed=False):\n",
    "    if not os.path.isdir(folder) or not os.path.isfile(\n",
    "            '/work/Alphas_and_Cyanos/aggregated/mad_roots-stricter_branch_lengths/%s' % folder):\n",
    "        return {folder: []}\n",
    "\n",
    "    aggregated = open(\n",
    "        '/work/Alphas_and_Cyanos/aggregated/mad_roots-stricter_branch_lengths/%s' % folder).read()\n",
    "    with cd(folder):\n",
    "        gene_tree     = {'named':ete3.Tree(linecache.getline('%s-MAD.ranger_out1' %folder, 8), format=1)}\n",
    "\n",
    "    gene_tree['support']        = root_like(gene_tree['named'], ete3.Tree('/work/Alphas_and_Cyanos/ranger_input_trees-no_long_branches/%s.tree' %folder))\n",
    "    gene_tree, duplicated_names = rename_branches(aggregated, gene_tree['support'])\n",
    "\n",
    "    ufboot_distribution = [node.support for node in gene_tree.traverse() if not node.is_leaf()]\n",
    "    if np.percentile(ufboot_distribution, 25) < 80:\n",
    "        return {folder:[[], gene_tree]}\n",
    "\n",
    "    num_replicates = float(re.match('Processed (\\d+) files', aggregated).group(1))\n",
    "\n",
    "    if not leaves_allowed:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = [^0]\\d+?\\], \\[Most Frequent mapping --> (n\\d+), (\\d+) times\\], \\[Most Frequent recipient --> (n\\d+), (\\d+) times\\].', aggregated, re.M)\n",
    "    else:\n",
    "        transfers = re.findall('^(m\\d+) = .*, Transfers = [^0]\\d+?\\], \\[Most Frequent mapping --> (\\S+), (\\d+) times\\], \\[Most Frequent recipient --> (\\S+), (\\d+) times\\].',   aggregated, re.M)\n",
    "\n",
    "    supported_transfers = []\n",
    "    for donor_map, donor, ranger_confidence_donor, recipient, ranger_confidence_recipient in transfers:\n",
    "        if int(ranger_confidence_donor) < threshold*num_replicates or int(ranger_confidence_recipient) < threshold*num_replicates:\n",
    "            continue\n",
    "        supported_transfers.append((donor_map, donor, recipient))\n",
    "\n",
    "    selected_transfers = []\n",
    "    for donor_map_name, donor_name, recipient_name in supported_transfers:\n",
    "        if donor_map_name in duplicated_names:\n",
    "            donor_map = gene_tree.search_nodes(name=duplicated_names[donor_map_name])[0]\n",
    "        else:\n",
    "            donor_map = gene_tree.search_nodes(name=donor_map_name)[0]\n",
    "        if donor_map.support < 95:\n",
    "            continue\n",
    "\n",
    "        recipient_map_search = re.search('^({children[0]}|{children[1]}).*Most Frequent mapping --> {recipient}'.format(\n",
    "            recipient=recipient_name,\n",
    "            children=[child.name for child in donor_map.children]),\n",
    "            aggregated, re.M)\n",
    "        if recipient_map_search:\n",
    "            recipient_map_name = recipient_map_search.group(1)\n",
    "            if not all([donor_name, recipient_name, donor_map_name, recipient_map_name]):\n",
    "                continue\n",
    "            selected_transfers.append({'donor':donor_name, 'recipient':recipient_name, 'donor_map':donor_map_name, 'recipient_map':recipient_map_name})\n",
    "\n",
    "    return {folder:[selected_transfers, gene_tree]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(group, transfers, tree, output_folder='index_transfer_trees/mad-90_threshold'):\n",
    "    gene_tree = tree.copy()\n",
    "    tmp_names = {}\n",
    "\n",
    "    for leaf in gene_tree.get_leaves():\n",
    "        genome_name, gene_name = leaf.name.split('_')\n",
    "        leaf.add_feature('genome', genome_name)\n",
    "\n",
    "    count = 0\n",
    "    for mappings in transfers:\n",
    "        if [mappings['donor'], mappings['recipient']] not in maxtic_compatible:\n",
    "            continue\n",
    "\n",
    "        donor_map     = gene_tree.search_nodes(name=mappings['donor_map']    )[0]\n",
    "        recipient_map = gene_tree.search_nodes(name=mappings['recipient_map'])[0]\n",
    "\n",
    "        donor_branch = reference_tree.search_nodes(name=mappings[ 'donor'])[0]\n",
    "        if 'annotation' not in donor_branch.features:\n",
    "            donor_branch.add_feature('annotation', {'donor':[], 'recipient':[]})\n",
    "        recipient_branch = reference_tree.search_nodes(name=mappings['recipient'])[0]\n",
    "        if 'annotation' not in recipient_branch.features:\n",
    "            recipient_branch.add_feature('annotation', {'donor':[], 'recipient':[]})\n",
    "\n",
    "        donor_branch.annotation['donor'].append([group, count])\n",
    "        recipient_branch.annotation['recipient'].append([group, count])\n",
    "\n",
    "        #\n",
    "        # set donor name\n",
    "        if not donor_map.name in tmp_names:\n",
    "            tmp_names[donor_map.name] = {'roles':[], 'hgt_count':[]}\n",
    "        tmp_names[donor_map.name]['roles'].append('donor%i' %count)\n",
    "        tmp_names[donor_map.name]['hgt_count'].append(str(count))\n",
    "\n",
    "        #\n",
    "        # set recipient name\n",
    "        if not recipient_map.name in tmp_names:\n",
    "            tmp_names[recipient_map.name] = {'roles':[], 'hgt_count':[]}\n",
    "        tmp_names[recipient_map.name]['roles'].append('recipient%i' %count)\n",
    "        tmp_names[recipient_map.name]['hgt_count'].append(str(count))\n",
    "\n",
    "        count += 1\n",
    "        del(donor_map, recipient_map)\n",
    "\n",
    "    features = {}\n",
    "    for node_name, feats in tmp_names.items():\n",
    "        node   = gene_tree.search_nodes(name=node_name)[0]\n",
    "        tmp_id = str(random.random())\n",
    "        features[tmp_id] = '[&support=%.2f,hgt_role=\"%s\",hgt_count=\"%s\",ranger_name=\"%s\"]' %(node.support, ', '.join(feats['roles']), ', '.join(feats['hgt_count']), node.name)\n",
    "        node.name = tmp_id\n",
    "\n",
    "\n",
    "    out  = open('%s/%s.Figtree.tree' %(output_folder, group), 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(gene_tree))\n",
    "    for node in gene_tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid         = genbank_summary.loc[node.genome, 'taxid']\n",
    "            lineage       = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(int(taxid))).items()}\n",
    "            lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out.write('\\t%s ' %(node.name))\n",
    "            comment = ['source_name=\"%s\"' % list(ncbi.get_taxid_translator([taxid]).values())[0]]\n",
    "            for rank in ['phylum', 'class', 'order', 'family', 'genus']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "        else:\n",
    "            if node.support and node.name.startswith('m'):\n",
    "                node.name = '[&support=%.2f,ranger_name=%s]' %(node.support, node.name)\n",
    "\n",
    "    newick_text = gene_tree.write(format=1)\n",
    "    newick_text = re.sub('_&support_(\\d+\\.\\d\\d)_ranger_name_(m\\d+)_', '[&support=\\\\1,ranger_name=\"\\\\2\"]', newick_text)\n",
    "    for key, value in features.items():\n",
    "        newick_text = newick_text.replace(key, value)\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Australodrepa oceanicum']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=ncbi.get_taxid_translator(['287698'])\n",
    "list(a.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>if transfers haven't been parsed yet</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with cd('reconciliations/mad_roots-stricter_branch_lengths'):\n",
    "    pool    = multiprocessing.Pool(processes=15)\n",
    "    results = pool.map(parse_aggregated, os.listdir('.'))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    transfers = {}\n",
    "    for filtered in results:\n",
    "        if  filtered.values() != [[]] and filtered.values()[0][0] != []:\n",
    "            transfers.update(filtered)\n",
    "\n",
    "out = open('aggregated/mad_transfers.pkl', 'w')\n",
    "pkl.dump(transfers, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>if transfers have already been parsed!</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = pkl.load(open('aggregated/mad_transfers.pkl', 'r+b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donor': 'n153',\n",
       " 'recipient': 'n499',\n",
       " 'donor_map': 'm305',\n",
       " 'recipient_map': 'm637'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfers['000437'][0][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 align=center>if MaxTic haven't been ran yet</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = open('aggregated/maxtic.constrains', 'w')\n",
    "for group, (transfer_data, gene_tree) in transfers.items():\n",
    "    for transfer in transfer_data:\n",
    "        out.write('%s\\t%s\\n' % (transfer['donor'], transfer['recipient']))\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_tree = ete3.Tree('rooted_partitions-with_named_branches.treefile', format=1)\n",
    "\n",
    "maxtic_compatible = [line.split()[:2]\n",
    "                     for line in open('aggregated/maxtic.constrains_MT_output_partial_order').read().split('\\n')\n",
    "                     if line]\n",
    "\n",
    "ncbi = ete3.NCBITaxa()\n",
    "header = 'assembly_accession bioproject biosample wgs_master refseq_category taxid species_taxid organism_name infraspecific_name isolate version_status assembly_level release_type genome_rep seq_rel_date asm_name submitter gbrs_paired_asm paired_asm_comp ftp_path excluded_from_refseq relation_to_type_material'.split()\n",
    "genbank_summary                     = pd.read_table('/work/assembly_summary_genbank.txt', comment='#', header=None, names=header, dtype={'taxid':str, 'infraspecific_name':str})\n",
    "genbank_summary['refseq_category']  = genbank_summary['refseq_category'].str.lower()\n",
    "genbank_summary['assembly_level']   = genbank_summary['assembly_level'].str.lower()\n",
    "genbank_summary['genome_rep']       = genbank_summary['genome_rep'].str.lower()\n",
    "genbank_summary.set_index('assembly_accession', inplace=True)\n",
    "genbank_summary.index               = [re.sub('\\.\\d+$', '', index).replace('_', '') for index in genbank_summary.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiberio/anaconda2/envs/py37/lib/python3.7/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning:\n",
      "\n",
      "taxid 1411903 was translated into 1267768\n",
      "\n",
      "/Users/thiberio/anaconda2/envs/py37/lib/python3.7/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning:\n",
      "\n",
      "taxid 1463601 was translated into 561184\n",
      "\n",
      "/Users/thiberio/anaconda2/envs/py37/lib/python3.7/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning:\n",
      "\n",
      "taxid 1535301 was translated into 561184\n",
      "\n",
      "/Users/thiberio/anaconda2/envs/py37/lib/python3.7/site-packages/ete3/ncbi_taxonomy/ncbiquery.py:240: UserWarning:\n",
      "\n",
      "taxid 340996 was translated into 561184\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group = '000437'\n",
    "for group, (transfer_data, gene_tree) in [[group, transfers[group]]]:\n",
    "    visualize_tree(group, transfer_data, gene_tree, output_folder='interesting_transfers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(group, transfers, tree, output_folder='index_transfer_trees/mad-90_threshold'):\n",
    "    gene_tree = tree.copy()\n",
    "    tmp_names = {}\n",
    "\n",
    "    for leaf in gene_tree.get_leaves():\n",
    "        genome_name, gene_name = leaf.name.split('_')\n",
    "        leaf.add_feature('genome', genome_name)\n",
    "\n",
    "    count = 0\n",
    "    for mappings in transfers:\n",
    "        if [mappings['donor'], mappings['recipient']] not in maxtic_compatible:\n",
    "            continue\n",
    "\n",
    "        donor_map     = gene_tree.search_nodes(name=mappings['donor_map']    )[0]\n",
    "        recipient_map = gene_tree.search_nodes(name=mappings['recipient_map'])[0]\n",
    "\n",
    "        donor_branch = reference_tree.search_nodes(name=mappings[ 'donor'])[0]\n",
    "        if 'annotation' not in donor_branch.features:\n",
    "            donor_branch.add_feature('annotation', {'donor':[], 'recipient':[]})\n",
    "        recipient_branch = reference_tree.search_nodes(name=mappings['recipient'])[0]\n",
    "        if 'annotation' not in recipient_branch.features:\n",
    "            recipient_branch.add_feature('annotation', {'donor':[], 'recipient':[]})\n",
    "\n",
    "        donor_branch.annotation['donor'].append([group, count])\n",
    "        recipient_branch.annotation['recipient'].append([group, count])\n",
    "\n",
    "        #\n",
    "        # set donor name\n",
    "        if not donor_map.name in tmp_names:\n",
    "            tmp_names[donor_map.name] = {'roles':[], 'hgt_count':[]}\n",
    "        tmp_names[donor_map.name]['roles'].append('donor%i' %count)\n",
    "        tmp_names[donor_map.name]['hgt_count'].append(str(count))\n",
    "\n",
    "        #\n",
    "        # set recipient name\n",
    "        if not recipient_map.name in tmp_names:\n",
    "            tmp_names[recipient_map.name] = {'roles':[], 'hgt_count':[]}\n",
    "        tmp_names[recipient_map.name]['roles'].append('recipient%i' %count)\n",
    "        tmp_names[recipient_map.name]['hgt_count'].append(str(count))\n",
    "\n",
    "        count += 1\n",
    "        del(donor_map, recipient_map)\n",
    "\n",
    "    features = {}\n",
    "    for node_name, feats in tmp_names.items():\n",
    "        node   = gene_tree.search_nodes(name=node_name)[0]\n",
    "        tmp_id = str(random.random())\n",
    "        features[tmp_id] = '[&support=%.2f,hgt_role=\"%s\",hgt_count=\"%s\",ranger_name=\"%s\"]' %(node.support, ', '.join(feats['roles']), ', '.join(feats['hgt_count']), node.name)\n",
    "        node.name = tmp_id\n",
    "\n",
    "\n",
    "    out  = open('%s/%s.Figtree.tree' %(output_folder, group), 'w')\n",
    "    out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(gene_tree))\n",
    "    for node in gene_tree.traverse():\n",
    "        if node.is_leaf():\n",
    "            taxid         = genbank_summary.loc[node.genome, 'taxid']\n",
    "            lineage       = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(int(taxid))).items()}\n",
    "            lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "            out.write('\\t%s ' %(node.name))\n",
    "            comment = ['source_name=\"%s\"' % list(ncbi.get_taxid_translator([taxid]).values())[0]]\n",
    "            for rank in ['phylum', 'class', 'order', 'family', 'genus']:\n",
    "                if rank in lineage:\n",
    "                    comment.append('tax_%s=\"%s\"' %(rank, lineage_names[lineage[rank]]))\n",
    "            out.write('[&%s]\\n' %' '.join(comment))\n",
    "\n",
    "        else:\n",
    "            if node.support and node.name.startswith('m'):\n",
    "                node.name = '[&support=%.2f,ranger_name=%s]' %(node.support, node.name)\n",
    "\n",
    "    newick_text = gene_tree.write(format=1)\n",
    "    newick_text = re.sub('_&support_(\\d+\\.\\d\\d)_ranger_name_(m\\d+)_', '[&support=\\\\1,ranger_name=\"\\\\2\"]', newick_text)\n",
    "    for key, value in features.items():\n",
    "        newick_text = newick_text.replace(key, value)\n",
    "    out.write(';\\nend;\\n')\n",
    "    out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out  = open('index_transfer_trees/mad-90_threshold/species_tree.Figtree.tree', 'w')\n",
    "out.write(\"#NEXUS\\nbegin taxa;\\n\\tdimensions ntax=%i;\\n\\ttaxlabels\\n\" %len(reference_tree))\n",
    "tmp_names = {}\n",
    "for node in reference_tree.traverse():\n",
    "    if node.is_leaf():\n",
    "        taxid = genbank_summary.loc[node.name, 'taxid']\n",
    "        lineage = {j: i for i, j in ncbi.get_rank(ncbi.get_lineage(int(taxid))).items()}\n",
    "        lineage_names = ncbi.get_taxid_translator(lineage.values())\n",
    "\n",
    "        out.write('\\t%s ' % (node.name))\n",
    "        comment = ['source_name=\"%s\"' % ncbi.get_taxid_translator([taxid]).itervalues().next()]\n",
    "        for rank in ['class', 'phylum', 'order']:\n",
    "            if rank in lineage:\n",
    "                comment.append('tax_%s=\"%s\"' % (rank, lineage_names[lineage[rank]]))\n",
    "        out.write('[&%s]\\n' %' '.join(comment))\n",
    "    else:\n",
    "        if 'annotation' in node.features:\n",
    "            tmp_id            = str(random.random())\n",
    "            tmp_names[tmp_id] = {'ranger_name':node.name}\n",
    "            node.name         = tmp_id\n",
    "            for group, count in node.annotation['donor']:\n",
    "                if group not in tmp_names[tmp_id]:\n",
    "                    tmp_names[tmp_id][group] = {'donor':[], 'recipient':[]}\n",
    "                tmp_names[tmp_id][group]['donor'].append(str(count))\n",
    "            for group, count in node.annotation['recipient']:\n",
    "                if group not in tmp_names[tmp_id]:\n",
    "                    tmp_names[tmp_id][group] = {'donor':[], 'recipient':[]}\n",
    "                tmp_names[tmp_id][group]['recipient'].append(str(count))\n",
    "\n",
    "newick_text = reference_tree.write(format=1)\n",
    "for key, value in tmp_names.items():\n",
    "    comment = []\n",
    "    for group, roles in value.items():\n",
    "        if group == 'ranger_name':\n",
    "            continue\n",
    "        donor_fragment = ''\n",
    "        if roles['donor']:\n",
    "            donor_fragment = 'donor%s' %','.join(roles['donor'])\n",
    "\n",
    "        recipient_fragment = ''\n",
    "        if roles['recipient']:\n",
    "            recipient_fragment = 'recipient%s' %','.join(roles['recipient'])\n",
    "\n",
    "        comment.append('%s_role=\"%s %s\"' %(group, donor_fragment, recipient_fragment) )\n",
    "\n",
    "    newick_text = newick_text.replace(key, '[&ranger_name=\"%s\",%s]' %(value['ranger_name'], ','.join(comment)))\n",
    "out.write(';\\nend;\\n')\n",
    "out.write('begin trees;\\n\\ttree tree_1 = [&R] %s\\nend;' %newick_text)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_dtl_dist((group, (transfer_data, gene_tree))):\n",
    "    dtl_distances   = []\n",
    "    donor_trees     = []\n",
    "    for transfer in transfer_data:\n",
    "        recipient_branch = gene_tree.search_nodes(name=transfer['recipient_map'])[0]\n",
    "        donor_branch     = recipient_branch.get_sisters()[0]\n",
    "        donor_trees.append(    donor_branch.write(    format=9))\n",
    "\n",
    "    os.system( 'cp species_tree.template tmp_ranger-%s.input' %(multiprocessing.current_process().name))\n",
    "    out = open('tmp_ranger-%s.input' %multiprocessing.current_process().name, 'a')\n",
    "    out.write('\\n'.join(donor_trees))\n",
    "    out.close()\n",
    "    os.system('/work/ranger/CorePrograms/Ranger-DTL.mac -q -i tmp_ranger-%s.input -o tmp_ranger-%s.output' %(multiprocessing.current_process().name, multiprocessing.current_process().name))\n",
    "    dtl_distances.extend([float(reconciliation_cost)/len(donor_tree) for reconciliation_cost, donor_tree in zip(\n",
    "        re.findall('^The minimum reconciliation cost is: (\\d+)',\n",
    "                   open('tmp_ranger-%s.output' %multiprocessing.current_process().name).read(),\n",
    "                   re.M\n",
    "                   ),\n",
    "        donor_trees)])\n",
    "\n",
    "    return {group:dtl_distances}\n",
    "\n",
    "pool = multiprocessing.Pool(processes=18)\n",
    "results = pool.map(assess_dtl_dist, transfers.items())\n",
    "\n",
    "donor_recipient_dtl_distances = {}\n",
    "for element in results:\n",
    "    donor_recipient_dtl_distances.update(element)\n",
    "\n",
    "out = open('aggregated/donor_subtree_DTL_costs.pkl', 'w')\n",
    "pkl.dump(donor_recipient_dtl_distances, out)\n",
    "out.close()\n",
    "\n",
    "maxtic_compatible = [line.split()[:2] for line in open('aggregated/maxtic.constrains_MT_output_partial_order').read().split('\\n') if line]\n",
    "\n",
    "transfer_distances       = {group:[] for group in transfers.keys()}\n",
    "for group, (transfer_data, gene_tree) in transfers.items():\n",
    "    for transfer in transfer_data:\n",
    "\n",
    "        donor_branch     = reference_tree.search_nodes(name=transfer['donor']    )[0]\n",
    "        recipient_branch = reference_tree.search_nodes(name=transfer['recipient'])[0]\n",
    "\n",
    "        transfer_distances[group].append(donor_branch.get_distance(recipient_branch, topology_only=False))\n",
    "\n",
    "tracer = {'color':[], 'x':[], 'y':[], 'text':[], 'linecolor':'transparent', 'marker':'circle', 'color_means':'Median tree aLRT support', 'marker_size':10}\n",
    "tracer = {'color':[], 'x':[], 'y':[], 'text':[]}\n",
    "for group in donor_recipient_dtl_distances.keys():\n",
    "    for position in range(len(donor_recipient_dtl_distances[group]['donor'])):\n",
    "        if [transfers[group][0][position]['donor'], transfers[group][0][position]['recipient']] not in maxtic_compatible:\n",
    "            continue\n",
    "\n",
    "        tracer['x'    ].append(transfer_distances[group][position])\n",
    "        tracer['y'    ].append(reference_tree.get_distance(transfers[group][0][position]['donor'], topology_only=False))\n",
    "        tracer['text' ].append('%s-#%i' %(group, position))\n",
    "        tracer['color'].append(donor_recipient_dtl_distances[group]['donor'][position])\n",
    "\n",
    "color_range          = np.linspace(np.min(tracer['color']), np.max(tracer['color']), 100)\n",
    "tracer['color_bins'] = np.digitize(tracer['color'], color_range)\n",
    "tracer_df = pd.DataFrame.from_dict(tracer)\n",
    "\n",
    "binned_df = tracer_df.groupby(by='color_bins')\n",
    "\n",
    "bins        = []\n",
    "for bin in binned_df.groups.keys():\n",
    "    tmp_df = binned_df.get_group(bin)\n",
    "    bins.append(go.Scatter(x=tmp_df.x.values, y=tmp_df.y.values, mode='markers', text=tmp_df.text.values, name=str(round(color_range[bin-1], 4)), hoverinfo='text', showlegend=False,\n",
    "                        marker=dict(size=10, color=tmp_df.color.values, colorscale='RdBu', cmax=tracer_df.color.values.max(), cmin=tracer_df.color.values.min(), symbol='circle', opacity=.7,\n",
    "               )))\n",
    "\n",
    "#\n",
    "# source: https://plot.ly/python/sliders/\n",
    "steps = [dict(label='All',\n",
    "                method='restyle',\n",
    "                args=[\n",
    "                    'visible', [True] * (len(bins) + 1)\n",
    "                ])\n",
    "]\n",
    "for i in range(len(bins)):\n",
    "    step = dict(label=bins[i]['name'],\n",
    "                method='restyle',\n",
    "                args=[\n",
    "#                    'visible', [False] * i + [True] * (len(bins) - i)\n",
    "                    'visible', [False]  * (len(bins))\n",
    "                ])\n",
    "    step['args'][1].append(True)\n",
    "    step['args'][1][i] = True\n",
    "    steps.append(step)\n",
    "slider = dict(steps=steps, currentvalue={'prefix':'Donor subtree DTL: '}, pad={'t':50})\n",
    "bins.append(go.Scatter(x=[np.min(tracer['x']), np.max(tracer['x'])], y=[np.min(tracer['y']), np.max(tracer['y'])], showlegend=False, mode='markers',\n",
    "                       marker=dict(size=10, color=[0.5], colorscale='RdBu', cmax=np.max(tracer['color']), cmin=np.min(tracer['color']), symbol='circle', opacity=0,\n",
    "                                    colorbar=dict(title='Donor subtree DTL cost'))\n",
    "                       ))\n",
    "\n",
    "layout    = go.Layout(title='Donor/Recipient subtree reconciliation costs', hovermode='closest', width=1200, height=1000,\n",
    "                      xaxis=dict(title='Donor-Recipient distance'),\n",
    "                      yaxis=dict(title='Donor closeness to root'),\n",
    "#                      legend=dict(orientation='h'),\n",
    "                      sliders=[slider])\n",
    "fig       = go.Figure(data=bins, layout=layout)\n",
    "plot      = plotly.offline.plot(fig, filename='./mad-donor_VS_recipient_DTL-tree_support.html', auto_open=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
